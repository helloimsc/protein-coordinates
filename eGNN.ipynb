{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cff622-fd4b-4efa-a191-7002af06593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eGNN\n",
    "import data_read\n",
    "import protein_residues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from Bio.SeqUtils import seq1, seq3\n",
    "from Bio.PDB import PDBIO, StructureBuilder\n",
    "import gc\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(\"cpu\")\n",
    "pdb_dir ='/mnt/rna01/nico/dynamics_project/learn/eGNN/data/dompdb/'\n",
    "list_path = \"/mnt/rna01/nico/dynamics_project/learn/eGNN/data/clean_pdb_id.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfe2f34-b69f-4706-82a4-8457eb6430ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = 10 #The std of protein coords is determined to be ~10 as indicated by data_processing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07660322-3a6d-4bc5-b5a9-948e78119d46",
   "metadata": {},
   "source": [
    "# New Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6548d2-e61f-41ee-9c4b-ca21e64b7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_res_object(pdb_seq,coords):\n",
    "    residues = []\n",
    "    for i ,aa in enumerate(pdb_seq, start=0):\n",
    "        if aa == \"G\":\n",
    "            res = {\"name\":seq3(aa),\"atoms\":[(\"N\", coords[i,0,:].tolist()), (\"CA\", coords[i,1,:].tolist()), (\"C\", coords[i,2,:].tolist())]}\n",
    "        else:\n",
    "            res = {\"name\":seq3(aa),\"atoms\":[(\"N\", coords[i,0,:].tolist()), (\"CA\", coords[i,1,:].tolist()), (\"C\", coords[i,2,:].tolist()),(\"CB\", coords[i,3,:].tolist())]}\n",
    "        residues.append(res)\n",
    "    return residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12ffbcb-bcdb-4ced-a658-918cb3a4d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdb(pdb_id,residues):\n",
    "    builder = StructureBuilder.StructureBuilder()\n",
    "    \n",
    "    # Create a structure object\n",
    "    builder.init_structure(\"Predicted eGNN Backbone \")\n",
    "    builder.init_model(0)\n",
    "    builder.init_chain(\"A\")  # Single chain \"A\"\n",
    "    builder.init_seg(\" \")\n",
    "    \n",
    "    for res_id, residue in enumerate(residues, start=1):\n",
    "        builder.init_residue(residue[\"name\"], \" \", res_id, \" \")\n",
    "    \n",
    "        # Add atoms to the residue\n",
    "        for atom_name, coords in residue[\"atoms\"]:\n",
    "            builder.init_atom(atom_name, coords, 1.0, 1.0, \" \", atom_name, res_id, atom_name[0])\n",
    "\n",
    "    structure = builder.get_structure()\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(pdb_id+\".pdb\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28453142-d0b5-44d9-8387-93e822851126",
   "metadata": {},
   "source": [
    "# Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cadbb1-99d6-4048-9346-9f3a72db2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "\n",
    "    def __init__(self, T, b_initial, b_final, device):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.beta = torch.linspace(b_initial,b_final,T).to(device)\n",
    "        \n",
    "    def _CoMGaussNoise(self, x_t1, t1, t2):\n",
    "        if t2 == 0:\n",
    "            a_mul = torch.prod(1-self.beta[0])\n",
    "        else:\n",
    "            a_mul = torch.prod(1-self.beta[t1:t2+1])\n",
    "        eps = torch.normal(mean=torch.zeros_like(x_t1),std=torch.ones_like(x_t1))\n",
    "        x1_mean = torch.mean(x_t1.flatten(end_dim=-2),dim=-2, keepdim=True)[None,:]\n",
    "        eps = eps - x1_mean \n",
    "        x_t2 = torch.sqrt(a_mul)*x_t1 + torch.sqrt(1-a_mul)*eps\n",
    "        return x_t2, eps\n",
    "\n",
    "    def _GaussNoise(self, x_t1, t1, t2):\n",
    "        if t2 == 0:\n",
    "            a_mul = torch.prod(1-self.beta[0])\n",
    "        else:\n",
    "            a_mul = torch.prod(1-self.beta[t1:t2+1])\n",
    "        eps = torch.normal(mean=torch.zeros_like(x_t1),std=torch.ones_like(x_t1))\n",
    "        x_t2 = torch.sqrt(a_mul)*x_t1 + torch.sqrt(1-a_mul)*eps\n",
    "        #Same output has the same shape as the input\n",
    "        return x_t2, eps\n",
    "        \n",
    "    def forward(self, x, h, t2):\n",
    "        x_perturbed, x_eps = self._GaussNoise(x, 0, t2)\n",
    "        h_perturbed, h_eps = self._GaussNoise(h,0,t2)\n",
    "        return x_perturbed, x_eps, h_perturbed, h_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0770438b-83d0-46e8-8697-23acf2e94bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generation(pdb_path,edge_device=\"cuda\"):\n",
    "    frames, seq = data_read.get_backbone(pdb_path)\n",
    "    frames = torch.from_numpy(frames[0]); seq = seq[0]\n",
    "    frames = frames.to(torch.float32)\n",
    "    n = len(seq)\n",
    "    seq_id = data_read.encode(seq[0])\n",
    "    \n",
    "#The default values as specifed by the DDPM paper(https://arxiv.org/pdf/2006.11239) are constants chosen \n",
    "#to be small relative to data scaled to [−1, 1] \n",
    "    \n",
    "    #Assumes fully connected graph\n",
    "    row =torch.arange(0,n).repeat_interleave(n).to(device)\n",
    "    col =torch.arange(0,n).repeat(n).to(device)\n",
    "    edge_id=(row,col)\n",
    "\n",
    "    return frames, seq, edge_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64609c75-1a1a-4ce7-8349-6ea40669a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prot_eGNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, process_device, gnn_device, embed_dim, sc_dim, in_node_nf, hidden_nf, out_node_nf,\n",
    "                 T, b_initial=0.0001, b_final=0.02, \n",
    "                 in_edge_nf=0, act_fn=nn.SiLU(), n_layers=6, residual=True, attention=True, normalize=False, tanh=False                 \n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sc_dim = sc_dim\n",
    "        self.process_device = process_device\n",
    "        self.gnn_device = gnn_device\n",
    "        self.T = T\n",
    "        \n",
    "        self.embedding = nn.Embedding(20,embed_dim)\n",
    "        self.diffusion = Diffusion(T, b_initial=0.0001, b_final=0.02, device=self.process_device) \n",
    "        self.EGNN = eGNN.EGNN(in_node_nf, hidden_nf, out_node_nf, in_edge_nf=0, \n",
    "                              device=self.gnn_device , act_fn=nn.SiLU(), n_layers=n_layers, residual=residual, attention=attention, normalize=normalize, tanh=tanh)\n",
    "\n",
    "    def _sc_embed(self, t):\n",
    "        half_dim = self.sc_dim//2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim,) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "    def sc_pos_embed(self, h):\n",
    "        t = torch.arange(0,h.shape[0])+1\n",
    "        half_dim = h.shape[-1]//2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim,) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        h += emb\n",
    "        return h\n",
    "        \n",
    "    def sample(self, seq_id):\n",
    "        #seq_id is a 1D tensor\n",
    "        x_t = torch.randn((seq_id.shape[0], 4, 3)).to(self.gnn_device) #N x 4 x 3\n",
    "        \n",
    "        #This remains constant, no need to recompute\n",
    "        n_aa = seq_id.shape[0]\n",
    "        seq_id=seq_id.to(self.gnn_device)\n",
    "        h = self.embedding(seq_id)\n",
    "        h = h.to(self.process_device)\n",
    "        h = self.sc_pos_embed(h) \n",
    "\n",
    "        #Generate Edges\n",
    "        row =torch.arange(0,n_aa).repeat_interleave(n_aa).to(self.gnn_device)\n",
    "        col =torch.arange(0,n_aa).repeat(n_aa).to(self.gnn_device)\n",
    "        edges_id=(row,col)\n",
    "        \n",
    "        for t in range(self.T-1, -1, -1):  \n",
    "            if t > 0:\n",
    "                z = torch.normal(mean=torch.zeros_like(x_t),std=torch.ones_like(x_t))\n",
    "            else:\n",
    "                z = torch.zeros_like(x_t)\n",
    "            sc_emb = self._sc_embed(torch.tensor([t+1])).repeat(n_aa, 1)\n",
    "            h_t = torch.cat((h,sc_emb),dim=-1)\n",
    "            h_t = h_t.to(self.gnn_device)\n",
    "            pred_h_eps, pred_x_eps= self.EGNN(h_t, x_t, edges_id, edge_attr=None)\n",
    "            if t != 0:\n",
    "                a_mul = torch.prod(1-self.diffusion.beta[0:t+1])\n",
    "                a_mul_1 = torch.prod(1-self.diffusion.beta[0:t])\n",
    "            else:\n",
    "                a_mul = torch.prod(1-self.diffusion.beta[t])\n",
    "                a_mul_1 = 0\n",
    "            a = 1-self.diffusion.beta[t]\n",
    "            #N.B. Vars = mul(Bt) for Xo ~ N(0,I) if Xo is a predetermined point the defined vars is prefered. See p.g.,3 of the DDPM paper\n",
    "            std = ((1-a_mul_1)/(1-a_mul))*self.diffusion.beta[t]\n",
    "            std= torch.sqrt(std)\n",
    "            x_t = (a**(-0.5))*(x_t- ((1-a)/(torch.sqrt(1-a_mul)))*pred_x_eps)+std*z\n",
    "        return x_t #Multiply the output by the global std\n",
    "        \n",
    "    def forward(self, x, seq_id, edges_id):\n",
    "        assert x.shape[0]==seq_id.shape[0], \"Sequence length and coordinate first dimension is not of the same shape!\"\n",
    "\n",
    "        n_aa = seq_id.shape[0]\n",
    "        seq_id=seq_id.to(self.gnn_device)\n",
    "        h = self.embedding(seq_id)\n",
    "        h = h.to(self.process_device)\n",
    "        h = self.sc_pos_embed(h)\n",
    "        \n",
    "        t2 = torch.randint(0, high=self.T, size=(1,))\n",
    "        sc_emb = self._sc_embed(t2+1).repeat(n_aa, 1)\n",
    "        x_perturbed, x_eps, h_perturbed, h_eps = self.diffusion(x,h,t2)\n",
    "        x_perturbed=x_perturbed.to(self.gnn_device)\n",
    "        h = torch.cat((h,sc_emb),dim=-1)\n",
    "        h = h.to(self.gnn_device)\n",
    "        #h_perturbed=h_perturbed.to(self.gnn_device)\n",
    "        pred_h_eps, pred_x_eps= self.EGNN(h, x_perturbed, edges_id, edge_attr=None)\n",
    "        return pred_h_eps, h_eps, pred_x_eps, x_eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90417a4e-a339-4ad0-8383-fdef90d0bee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Params\n",
    "#Num of clean proteins 31065\n",
    "steps = 20000\n",
    "batch_size = 500\n",
    "with open(list_path) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "np.random.seed(seed=17)\n",
    "np.random.shuffle(lines)\n",
    "train_list = np.array(lines[:-len(lines)//5])\n",
    "val_list = np.array(lines[-len(lines)//5:])\n",
    "np.savetxt(\"train_list.csv\", train_list, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"val_list.csv\", val_list, delimiter=\",\", fmt='%s')\n",
    "#Instantiate Models \n",
    "embed_dim = 64\n",
    "sc_dim = 32\n",
    "in_node_nf = embed_dim + sc_dim\n",
    "hidden_nf =128\n",
    "out_node_nf = 64\n",
    "\n",
    "model = prot_eGNN(\"cpu\", \"cuda\" , embed_dim, sc_dim, in_node_nf, hidden_nf, out_node_nf,\n",
    "                 10000, b_initial=0.0001, b_final=0.02, \n",
    "                 in_edge_nf=0, act_fn=nn.SiLU(), n_layers=5, residual=True, attention=True, normalize=False, tanh=False)\n",
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57d036b-5d09-48fc-9f7e-050dcac347e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss here\n",
    "denoising_loss = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.01, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d0bd-245f-492a-996b-e1985131f9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                              | 257/20000 [00:10<13:39, 24.09it/s]"
     ]
    }
   ],
   "source": [
    "#Training Loop 1\n",
    "g_pdb_dir=\"/mnt/rna01/nico/dynamics_project/learn/eGNN/generated_pdb/\"\n",
    "model.train()\n",
    "agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "for i in tqdm(range(steps)):\n",
    "    pdb_path = pdb_dir+np.random.choice(train_list)\n",
    "    try:\n",
    "        frames,seq,edges=input_generation(pdb_path)\n",
    "    except:\n",
    "        continue\n",
    "    CoM = torch.mean(frames.flatten(end_dim=-2),dim=-2, keepdim=True)\n",
    "    frames = frames - CoM[None,:]\n",
    "    frames = frames/data_std\n",
    "    i_seq = data_read.encode(seq)\n",
    "    \n",
    "    pred_h_eps, h_eps, pred_x_eps, x_eps=model(frames, i_seq, edges)\n",
    "\n",
    "    \n",
    "    x_eps = x_eps.to(\"cuda\")\n",
    "    loss = denoising_loss(pred_x_eps,x_eps)\n",
    "    agg_loss +=loss\n",
    "    if (i+1)%500 == 0:\n",
    "        print(f\"{i+1} Step : {loss}\")\n",
    "        print(f\"{i+1} Step : {agg_loss/500}\")\n",
    "        print(type(agg_loss))\n",
    "        agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "        torch.save({\n",
    "            'epoch': i+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'step_loss': agg_loss\n",
    "            }, f'./model_weights/prot_eGNN_{i+1}')\n",
    "        model.eval()\n",
    "        if i>9999:\n",
    "            for j in val_list[:30]:\n",
    "                v_frames,v_seq,v_edges=input_generation(pdb_dir+j)\n",
    "                del v_frames\n",
    "                del v_edges\n",
    "                gc.collect()\n",
    "                v_i_seq = data_read.encode(v_seq)\n",
    "                with torch.no_grad():\n",
    "                    coords=model.sample(v_i_seq)\n",
    "                    coords=coords*data_std\n",
    "                res = generate_res_object(v_seq,coords)\n",
    "                generate_pdb(g_pdb_dir+f\"pred_{j}_model_{i+1}\",res)  \n",
    "        model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304689a-d860-4b88-929b-36106bd7ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                              | 242/20000 [00:09<10:03, 32.73it/s]"
     ]
    }
   ],
   "source": [
    "# Training Loop 2\n",
    "g_pdb_dir=\"/mnt/rna01/nico/dynamics_project/learn/eGNN/generated_pdb/\"\n",
    "model.train()\n",
    "agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "for i in tqdm(range(steps)):\n",
    "    pdb_path = pdb_dir+np.random.choice(train_list)\n",
    "    try:\n",
    "        frames,seq,edges=input_generation(pdb_path)\n",
    "    except:\n",
    "        continue\n",
    "    if len(seq)>400:continue\n",
    "    CoM = torch.mean(frames.flatten(end_dim=-2),dim=-2, keepdim=True)\n",
    "    frames = frames - CoM[None,:]\n",
    "    frames = frames/data_std\n",
    "    i_seq = data_read.encode(seq)\n",
    "    \n",
    "    pred_h_eps, h_eps, pred_x_eps, x_eps=model(frames, i_seq, edges)\n",
    "\n",
    "    \n",
    "    x_eps = x_eps.to(\"cuda\")\n",
    "    loss = denoising_loss(pred_x_eps,x_eps)\n",
    "    loss.backward()\n",
    "    agg_loss +=loss\n",
    "    if (i+1)%batch_size ==0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if (i+1)%500 == 0:\n",
    "        print(f\"{i+1} Step : {loss}\")\n",
    "        print(f\"{i+1} Step : {agg_loss/500}\")\n",
    "        print(type(agg_loss))\n",
    "        torch.save({\n",
    "            'epoch': i+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'step_loss': agg_loss[0]\n",
    "            }, f'./model_weights/prot_eGNN_{i+1}')\n",
    "        agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "        if i>500:\n",
    "            model.eval()\n",
    "            for j in val_list[:30]:\n",
    "                v_frames,v_seq,v_edges=input_generation(pdb_dir+j)\n",
    "                del v_frames\n",
    "                del v_edges\n",
    "                gc.collect()\n",
    "                v_i_seq = data_read.encode(v_seq)\n",
    "                with torch.no_grad():\n",
    "                    coords=model.sample(v_i_seq)\n",
    "                    coords=coords*data_std\n",
    "                res = generate_res_object(v_seq,coords)\n",
    "                generate_pdb(g_pdb_dir+f\"pred_{j}_model_{i+1}\",res)  \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba19740-d100-468c-9d76-0c78ab149d76",
   "metadata": {},
   "source": [
    "# Generate Some PDB Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f0f69-09e1-4f90-b402-4be5ba5763d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i in val_list[:10]:\n",
    "    v_frames,v_seq,v_edges=input_generation(pdb_dir+i)\n",
    "    del v_frames\n",
    "    del v_edges\n",
    "    gc.collect()\n",
    "    v_i_seq = data_read.encode(v_seq)\n",
    "    with torch.no_grad():\n",
    "        coords=model.sample(v_i_seq)\n",
    "        coords=coords*10\n",
    "    res = generate_res_object(v_seq,coords)\n",
    "    generate_pdb(g_pdb_dir+i,res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
