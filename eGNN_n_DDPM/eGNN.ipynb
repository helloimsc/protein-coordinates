{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cff622-fd4b-4efa-a191-7002af06593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eGNN\n",
    "import data_read\n",
    "import protein_residues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from Bio.SeqUtils import seq1, seq3\n",
    "from Bio.PDB import PDBIO, StructureBuilder\n",
    "import gc\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(\"cpu\")\n",
    "pdb_dir ='/mnt/rna01/nico/dynamics_project/learn/eGNN/data/dompdb/'\n",
    "list_path = \"/mnt/rna01/nico/dynamics_project/learn/eGNN/data/clean_pdb_id.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfe2f34-b69f-4706-82a4-8457eb6430ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = 10 #The std of protein coords is determined to be ~10 as indicated by data_processing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07660322-3a6d-4bc5-b5a9-948e78119d46",
   "metadata": {},
   "source": [
    "# New Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e33b52-613c-4eee-a8f5-e17df32b4e25",
   "metadata": {},
   "source": [
    "Define some functions that were not placed inside the Python scripts. \n",
    "generate_res_object => Creates a dictionary from the pdb_seq {str} and the coordinates of the backbone {torch.tensor}\n",
    "generate_pdb        => Creates a PDB file from residues {dictionary} with name pdb_id {string}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6548d2-e61f-41ee-9c4b-ca21e64b7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_res_object(pdb_seq,coords):\n",
    "    residues = []\n",
    "    for i ,aa in enumerate(pdb_seq, start=0):\n",
    "        if aa == \"G\": #If the amino acid is a glycine, do not add CB as there is no CB in glycine\n",
    "            res = {\"name\":seq3(aa),\"atoms\":[(\"N\", coords[i,0,:].tolist()), (\"CA\", coords[i,1,:].tolist()), (\"C\", coords[i,2,:].tolist())]}\n",
    "        else:\n",
    "            res = {\"name\":seq3(aa),\"atoms\":[(\"N\", coords[i,0,:].tolist()), (\"CA\", coords[i,1,:].tolist()), (\"C\", coords[i,2,:].tolist()),(\"CB\", coords[i,3,:].tolist())]}\n",
    "        residues.append(res)\n",
    "    return residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12ffbcb-bcdb-4ced-a658-918cb3a4d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdb(pdb_id,residues):\n",
    "    builder = StructureBuilder.StructureBuilder()\n",
    "    \n",
    "    # Create a structure object\n",
    "    builder.init_structure(\"Predicted eGNN Backbone \")\n",
    "    builder.init_model(0)\n",
    "    builder.init_chain(\"A\")  # Single chain \"A\"\n",
    "    builder.init_seg(\" \")\n",
    "    \n",
    "    for res_id, residue in enumerate(residues, start=1):\n",
    "        builder.init_residue(residue[\"name\"], \" \", res_id, \" \")\n",
    "    \n",
    "        # Add atoms to the residue\n",
    "        for atom_name, coords in residue[\"atoms\"]:\n",
    "            builder.init_atom(atom_name, coords, 1.0, 1.0, \" \", atom_name, res_id, atom_name[0])\n",
    "\n",
    "    structure = builder.get_structure()\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(pdb_id+\".pdb\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28453142-d0b5-44d9-8387-93e822851126",
   "metadata": {},
   "source": [
    "# Objects\n",
    "Create model from multiple Pytorch objects. prot_eGNN is the final model which takes in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cadbb1-99d6-4048-9346-9f3a72db2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "\n",
    "    def __init__(self, T, b_initial, b_final, device):\n",
    "        super().__init__()\n",
    "        self.T = T #Maximum Timestep\n",
    "        self.beta = torch.linspace(b_initial,b_final,T).to(device) #Define linear beta schedule\n",
    "        \n",
    "    def _CoMGaussNoise(self, x_t1, t1, t2): #Diffusion w.r.t., to the centre of mass as proposed by the E(3) diffusion https://arxiv.org/abs/2203.17003\n",
    "        if t2 == 0:\n",
    "            a_mul = torch.prod(1-self.beta[0])\n",
    "        else:\n",
    "            a_mul = torch.prod(1-self.beta[t1:t2+1])\n",
    "        eps = torch.normal(mean=torch.zeros_like(x_t1),std=torch.ones_like(x_t1))\n",
    "        x1_mean = torch.mean(x_t1.flatten(end_dim=-2),dim=-2, keepdim=True)[None,:]\n",
    "        eps = eps - x1_mean \n",
    "        x_t2 = torch.sqrt(a_mul)*x_t1 + torch.sqrt(1-a_mul)*eps\n",
    "        return x_t2, eps\n",
    "\n",
    "    def _GaussNoise(self, x_t1, t1, t2): #Normal diffusion as proposed by the DDPM paper\n",
    "        if t2 == 0:\n",
    "            a_mul = torch.prod(1-self.beta[0])\n",
    "        else:\n",
    "            a_mul = torch.prod(1-self.beta[t1:t2+1])\n",
    "        eps = torch.normal(mean=torch.zeros_like(x_t1),std=torch.ones_like(x_t1))\n",
    "        x_t2 = torch.sqrt(a_mul)*x_t1 + torch.sqrt(1-a_mul)*eps\n",
    "        #Same output has the same shape as the input\n",
    "        return x_t2, eps\n",
    "        \n",
    "    def forward(self, x, h, t2):\n",
    "        x_perturbed, x_eps = self._GaussNoise(x, 0, t2)\n",
    "        h_perturbed, h_eps = self._GaussNoise(h,0,t2)\n",
    "        return x_perturbed, x_eps, h_perturbed, h_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0770438b-83d0-46e8-8697-23acf2e94bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generation(pdb_path,edge_device=\"cuda\"): #Takes a PDB path and generate a torch tensor of the backbone coordinates (frames), edges defined by the node indexes (edge_id) and the 1 letter representation of each amino acid as defined by the \n",
    "                                                   # IUPAC convention https://iupac.qmul.ac.uk/AminoAcid/A2021.html\n",
    "    frames, seq = data_read.get_backbone(pdb_path)\n",
    "    frames = torch.from_numpy(frames[0]); seq = seq[0]\n",
    "    frames = frames.to(torch.float32)\n",
    "    n = len(seq)\n",
    "    seq_id = data_read.encode(seq[0])\n",
    "    \n",
    "    \n",
    "    #Assumes fully connected graph\n",
    "    row =torch.arange(0,n).repeat_interleave(n).to(device)\n",
    "    col =torch.arange(0,n).repeat(n).to(device)\n",
    "    edge_id=(row,col)\n",
    "\n",
    "    return frames, seq, edge_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64609c75-1a1a-4ce7-8349-6ea40669a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper class that combines an eGNN and a Diffusion module\n",
    "class prot_eGNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, process_device, gnn_device, embed_dim, sc_dim, in_node_nf, hidden_nf, out_node_nf,\n",
    "                 T, b_initial=0.0001, b_final=0.02, \n",
    "                 in_edge_nf=0, act_fn=nn.SiLU(), n_layers=6, residual=True, attention=True, normalize=False, tanh=False                 \n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sc_dim = sc_dim\n",
    "        self.process_device = process_device\n",
    "        self.gnn_device = gnn_device\n",
    "        self.T = T\n",
    "        \n",
    "        self.embedding = nn.Embedding(20,embed_dim)\n",
    "        self.diffusion = Diffusion(T, b_initial=0.0001, b_final=0.02, device=self.process_device) \n",
    "        self.EGNN = eGNN.EGNN(in_node_nf, hidden_nf, out_node_nf, in_edge_nf=0, \n",
    "                              device=self.gnn_device , act_fn=nn.SiLU(), n_layers=n_layers, residual=residual, attention=attention, normalize=normalize, tanh=tanh)\n",
    "\n",
    "    def _sc_embed(self, t): #sc embedding of the noising timestep as proposed by the DDPM (https://arxiv.org/pdf/2006.11239)\n",
    "        half_dim = self.sc_dim//2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim,) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "    def sc_pos_embed(self, h): # Sequence position embedding as used in ESMFold (https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)\n",
    "        t = torch.arange(0,h.shape[0])+1\n",
    "        half_dim = h.shape[-1]//2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim,) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        h += emb\n",
    "        return h\n",
    "        \n",
    "    def sample(self, seq_id): #Sampling process as defined by the DDPM paper\n",
    "        #seq_id is a 1D tensor\n",
    "        x_t = torch.randn((seq_id.shape[0], 4, 3)).to(self.gnn_device) #N x 4 x 3\n",
    "        \n",
    "        #This remains constant, no need to recompute\n",
    "        n_aa = seq_id.shape[0]\n",
    "        seq_id=seq_id.to(self.gnn_device)\n",
    "        h = self.embedding(seq_id)\n",
    "        h = h.to(self.process_device)\n",
    "        h = self.sc_pos_embed(h) \n",
    "\n",
    "        #Generate Edges\n",
    "        row =torch.arange(0,n_aa).repeat_interleave(n_aa).to(self.gnn_device)\n",
    "        col =torch.arange(0,n_aa).repeat(n_aa).to(self.gnn_device)\n",
    "        edges_id=(row,col)\n",
    "        \n",
    "        for t in range(self.T-1, -1, -1):  \n",
    "            if t > 0:\n",
    "                z = torch.normal(mean=torch.zeros_like(x_t),std=torch.ones_like(x_t))\n",
    "            else:\n",
    "                z = torch.zeros_like(x_t)\n",
    "            sc_emb = self._sc_embed(torch.tensor([t+1])).repeat(n_aa, 1)\n",
    "            h_t = torch.cat((h,sc_emb),dim=-1)\n",
    "            h_t = h_t.to(self.gnn_device)\n",
    "            pred_h_eps, pred_x_eps= self.EGNN(h_t, x_t, edges_id, edge_attr=None)\n",
    "            if t != 0:\n",
    "                a_mul = torch.prod(1-self.diffusion.beta[0:t+1])\n",
    "                a_mul_1 = torch.prod(1-self.diffusion.beta[0:t])\n",
    "            else:\n",
    "                a_mul = torch.prod(1-self.diffusion.beta[t])\n",
    "                a_mul_1 = 0\n",
    "            a = 1-self.diffusion.beta[t]\n",
    "            #N.B. Vars = mul(Bt) for Xo ~ N(0,I) if Xo is a predetermined point the defined vars is prefered. See p.g.,3 of the DDPM paper\n",
    "            std = ((1-a_mul_1)/(1-a_mul))*self.diffusion.beta[t]\n",
    "            std= torch.sqrt(std)\n",
    "            x_t = (a**(-0.5))*(x_t- ((1-a)/(torch.sqrt(1-a_mul)))*pred_x_eps)+std*z\n",
    "        return x_t #Multiply the output by the global std\n",
    "        \n",
    "    def forward(self, x, seq_id, edges_id): #Takes the backbone coordinates, sequence id, edges, and adds noise prior to passing it to the eGNN\n",
    "        assert x.shape[0]==seq_id.shape[0], \"Sequence length and coordinate first dimension is not of the same shape!\"\n",
    "\n",
    "        n_aa = seq_id.shape[0]\n",
    "        seq_id=seq_id.to(self.gnn_device)\n",
    "        h = self.embedding(seq_id)\n",
    "        h = h.to(self.process_device)\n",
    "        h = self.sc_pos_embed(h)\n",
    "        \n",
    "        t2 = torch.randint(0, high=self.T, size=(1,))\n",
    "        sc_emb = self._sc_embed(t2+1).repeat(n_aa, 1)\n",
    "        x_perturbed, x_eps, h_perturbed, h_eps = self.diffusion(x,h,t2)\n",
    "        x_perturbed=x_perturbed.to(self.gnn_device)\n",
    "        h = torch.cat((h,sc_emb),dim=-1)\n",
    "        h = h.to(self.gnn_device)\n",
    "        #h_perturbed=h_perturbed.to(self.gnn_device)\n",
    "        pred_h_eps, pred_x_eps= self.EGNN(h, x_perturbed, edges_id, edge_attr=None)\n",
    "        return pred_h_eps, h_eps, pred_x_eps, x_eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90417a4e-a339-4ad0-8383-fdef90d0bee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Params\n",
    "#Num of clean proteins 31065\n",
    "steps = 20000\n",
    "batch_size = 500\n",
    "with open(list_path) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "np.random.seed(seed=17)\n",
    "np.random.shuffle(lines)\n",
    "train_list = np.array(lines[:-len(lines)//5])\n",
    "val_list = np.array(lines[-len(lines)//5:])\n",
    "np.savetxt(\"train_list.csv\", train_list, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"val_list.csv\", val_list, delimiter=\",\", fmt='%s')\n",
    "#Instantiate Models \n",
    "embed_dim = 64\n",
    "sc_dim = 32\n",
    "in_node_nf = embed_dim + sc_dim\n",
    "hidden_nf =128\n",
    "out_node_nf = 64\n",
    "\n",
    "model = prot_eGNN(\"cpu\", \"cuda\" , embed_dim, sc_dim, in_node_nf, hidden_nf, out_node_nf,\n",
    "                 800, b_initial=0.0001, b_final=0.02, \n",
    "                 in_edge_nf=0, act_fn=nn.SiLU(), n_layers=5, residual=True, attention=True, normalize=False, tanh=False)\n",
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57d036b-5d09-48fc-9f7e-050dcac347e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss here\n",
    "denoising_loss = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.01, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41b464-ada0-4886-97f5-576902594f92",
   "metadata": {},
   "source": [
    "Attempted different training loss as when training naively we observed some training loss instability. The training loss instability is solved after data normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d0bd-245f-492a-996b-e1985131f9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                              | 257/20000 [00:10<13:39, 24.09it/s]"
     ]
    }
   ],
   "source": [
    "#Training Loop 1 (Training by batches)\n",
    "g_pdb_dir=\"/mnt/rna01/nico/dynamics_project/learn/eGNN/generated_pdb/\"\n",
    "model.train()\n",
    "agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "for i in tqdm(range(steps)):\n",
    "    pdb_path = pdb_dir+np.random.choice(train_list)\n",
    "    try:\n",
    "        frames,seq,edges=input_generation(pdb_path)\n",
    "    except:\n",
    "        continue\n",
    "    CoM = torch.mean(frames.flatten(end_dim=-2),dim=-2, keepdim=True)\n",
    "    frames = frames - CoM[None,:]\n",
    "    frames = frames/data_std\n",
    "    i_seq = data_read.encode(seq)\n",
    "    \n",
    "    pred_h_eps, h_eps, pred_x_eps, x_eps=model(frames, i_seq, edges)\n",
    "\n",
    "    \n",
    "    x_eps = x_eps.to(\"cuda\")\n",
    "    loss = denoising_loss(pred_x_eps,x_eps)\n",
    "    agg_loss +=loss\n",
    "    if (i+1)%500 == 0: #Print loss\n",
    "        print(f\"{i+1} Step : {loss}\")\n",
    "        print(f\"{i+1} Step : {agg_loss/500}\")\n",
    "        print(type(agg_loss))\n",
    "        agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "        torch.save({\n",
    "            'epoch': i+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'step_loss': agg_loss\n",
    "            }, f'./model_weights/prot_eGNN_{i+1}')\n",
    "        model.eval()\n",
    "        if i>9999: #Generate some structures after training and save them as PDB files\n",
    "            for j in val_list[:30]:\n",
    "                v_frames,v_seq,v_edges=input_generation(pdb_dir+j)\n",
    "                del v_frames\n",
    "                del v_edges\n",
    "                gc.collect()\n",
    "                v_i_seq = data_read.encode(v_seq)\n",
    "                with torch.no_grad():\n",
    "                    coords=model.sample(v_i_seq)\n",
    "                    coords=coords*data_std\n",
    "                res = generate_res_object(v_seq,coords)\n",
    "                generate_pdb(g_pdb_dir+f\"pred_{j}_model_{i+1}\",res)  \n",
    "        model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c304689a-d860-4b88-929b-36106bd7ec5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                             | 498/20000 [00:17<09:24, 34.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Step : 0.5745052695274353\n",
      "500 Step : tensor([0.5515], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                          | 1003/20000 [00:35<11:56, 26.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Step : 1.7658617496490479\n",
      "1000 Step : tensor([0.4631], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▊                                                                        | 1503/20000 [00:51<08:52, 34.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 Step : 0.1382541060447693\n",
      "1500 Step : tensor([0.4537], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                      | 2003/20000 [01:08<11:30, 26.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 Step : 0.005201550666242838\n",
      "2000 Step : tensor([0.4711], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▊                                                                    | 2500/20000 [01:25<09:21, 31.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 Step : 0.17913168668746948\n",
      "2500 Step : tensor([0.4584], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▋                                                                  | 3004/20000 [01:42<08:33, 33.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 Step : 0.4811536371707916\n",
      "3000 Step : tensor([0.4154], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▋                                                                | 3504/20000 [01:58<09:21, 29.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500 Step : 0.47320646047592163\n",
      "3500 Step : tensor([0.4075], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▌                                                              | 4005/20000 [02:16<10:39, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 Step : 0.008586352691054344\n",
      "4000 Step : tensor([0.4290], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▌                                                            | 4505/20000 [02:32<08:10, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 Step : 0.003172078635543585\n",
      "4500 Step : tensor([0.4180], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▌                                                          | 5003/20000 [02:50<10:29, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Step : 0.031799621880054474\n",
      "5000 Step : tensor([0.3630], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▍                                                        | 5502/20000 [03:07<08:19, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500 Step : 0.0016593351028859615\n",
      "5500 Step : tensor([0.4137], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▍                                                      | 6003/20000 [03:24<07:52, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 Step : 0.0015464074676856399\n",
      "6000 Step : tensor([0.3718], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████▎                                                    | 6502/20000 [03:42<08:01, 28.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500 Step : 1.1315107345581055\n",
      "6500 Step : tensor([0.3704], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████▎                                                  | 7004/20000 [03:59<08:44, 24.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 Step : 0.0013609816087409854\n",
      "7000 Step : tensor([0.3818], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████▎                                                | 7501/20000 [04:15<08:15, 25.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500 Step : 0.04701844975352287\n",
      "7500 Step : tensor([0.3687], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▏                                              | 8002/20000 [04:32<07:03, 28.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 Step : 0.03780105337500572\n",
      "8000 Step : tensor([0.5123], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▏                                            | 8503/20000 [04:48<06:28, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 Step : 0.07415009289979935\n",
      "8500 Step : tensor([0.3835], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████                                           | 9006/20000 [05:05<07:18, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 Step : 0.03502056002616882\n",
      "9000 Step : tensor([0.3481], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████                                         | 9503/20000 [05:22<05:57, 29.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500 Step : 1.7008038759231567\n",
      "9500 Step : tensor([0.3604], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▌                                      | 10003/20000 [05:38<04:54, 33.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Step : 0.1585865169763565\n",
      "10000 Step : tensor([0.3924], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████▍                                    | 10497/20000 [05:55<04:42, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500 Step : 0.25409287214279175\n",
      "10500 Step : tensor([0.5464], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████▍                                    | 10499/20000 [07:16<06:35, 24.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m v_i_seq \u001b[38;5;241m=\u001b[39m data_read\u001b[38;5;241m.\u001b[39mencode(v_seq)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 46\u001b[0m     coords\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_i_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     coords\u001b[38;5;241m=\u001b[39mcoords\u001b[38;5;241m*\u001b[39mdata_std\n\u001b[1;32m     48\u001b[0m res \u001b[38;5;241m=\u001b[39m generate_res_object(v_seq,coords)\n",
      "Cell \u001b[0;32mIn[7], line 55\u001b[0m, in \u001b[0;36mprot_eGNN.sample\u001b[0;34m(self, seq_id)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):  \n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(x_t)\n",
      "File \u001b[0;32m~/miniconda3/envs/gvp/lib/python3.11/site-packages/torch/utils/_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop 2 (Training on each step)\n",
    "g_pdb_dir=\"/mnt/rna01/nico/dynamics_project/learn/eGNN/generated_pdb/\"\n",
    "model.train()\n",
    "agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "for i in tqdm(range(steps)):\n",
    "    pdb_path = pdb_dir+np.random.choice(train_list)\n",
    "    try:\n",
    "        frames,seq,edges=input_generation(pdb_path)\n",
    "    except:\n",
    "        continue\n",
    "    if len(seq)>400:continue\n",
    "    CoM = torch.mean(frames.flatten(end_dim=-2),dim=-2, keepdim=True)\n",
    "    frames = frames - CoM[None,:]\n",
    "    frames = frames/data_std\n",
    "    i_seq = data_read.encode(seq)\n",
    "    \n",
    "    pred_h_eps, h_eps, pred_x_eps, x_eps=model(frames, i_seq, edges)\n",
    "\n",
    "    \n",
    "    x_eps = x_eps.to(\"cuda\")\n",
    "    loss = denoising_loss(pred_x_eps,x_eps)\n",
    "    loss.backward()\n",
    "    agg_loss +=loss\n",
    "    if (i+1)%batch_size ==0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if (i+1)%500 == 0:\n",
    "        print(f\"{i+1} Step : {loss}\")\n",
    "        print(f\"{i+1} Step : {agg_loss/500}\")\n",
    "        print(type(agg_loss))\n",
    "        torch.save({\n",
    "            'epoch': i+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'step_loss': agg_loss[0]\n",
    "            }, f'./model_weights/prot_eGNN_{i+1}')\n",
    "        agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "        if i>10000:\n",
    "            model.eval()\n",
    "            for j in val_list[:30]:\n",
    "                v_frames,v_seq,v_edges=input_generation(pdb_dir+j)\n",
    "                del v_frames\n",
    "                del v_edges\n",
    "                gc.collect()\n",
    "                v_i_seq = data_read.encode(v_seq)\n",
    "                with torch.no_grad():\n",
    "                    coords=model.sample(v_i_seq)\n",
    "                    coords=coords*data_std\n",
    "                res = generate_res_object(v_seq,coords)\n",
    "                generate_pdb(g_pdb_dir+f\"pred_{j}_model_{i+1}\",res)  \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72002654-5a9c-4698-96cd-6541b7cb67d7",
   "metadata": {},
   "source": [
    "# Debugging Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50aaafd5-c293-44a8-997c-4ba4f2b4efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "#Num of clean proteins 31065\n",
    "steps = 1001\n",
    "batch_size = 500\n",
    "with open(list_path) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "np.random.seed(seed=17)\n",
    "np.random.shuffle(lines)\n",
    "train_list = np.array(lines[:-len(lines)//5])\n",
    "val_list = np.array(lines[-len(lines)//5:])\n",
    "np.savetxt(\"train_list.csv\", train_list, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"val_list.csv\", val_list, delimiter=\",\", fmt='%s')\n",
    "#Instantiate Models \n",
    "embed_dim = 64\n",
    "sc_dim = 32\n",
    "in_node_nf = embed_dim + sc_dim\n",
    "hidden_nf =128\n",
    "out_node_nf = 64\n",
    "\n",
    "model = prot_eGNN(\"cpu\", \"cuda\" , embed_dim, sc_dim, in_node_nf, hidden_nf, out_node_nf,\n",
    "                 800, b_initial=0.0001, b_final=0.02, \n",
    "                 in_edge_nf=0, act_fn=nn.SiLU(), n_layers=5, residual=True, attention=True, normalize=False, tanh=False)\n",
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e624a17-6e00-4460-8dce-5983d48f0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss here\n",
    "denoising_loss = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.01, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6decafbb-0c75-4546-8096-a8198b59cb83",
   "metadata": {},
   "source": [
    "Tried to overfit on one model to see if the model learns correctly. Similar loss is observed as when training on a large dataset implying that there is some bugs with the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae61b4-ce9f-4772-b58a-1572dc868b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4h7wA00']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▎                                       | 504/1001 [00:19<00:21, 23.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Step : 0.010035381652414799\n",
      "500 Step : tensor([0.4285], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████                          | 676/1001 [00:26<00:11, 27.39it/s]"
     ]
    }
   ],
   "source": [
    "# Overfitting Attempt\n",
    "g_pdb_dir=\"/mnt/rna01/nico/dynamics_project/learn/eGNN/generated_pdb/\"\n",
    "model.train()\n",
    "agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "train_list = [train_list[0]]\n",
    "print(train_list)\n",
    "for i in tqdm(range(steps)):\n",
    "    pdb_path = pdb_dir+np.random.choice(train_list)\n",
    "    try:\n",
    "        frames,seq,edges=input_generation(pdb_path)\n",
    "    except:\n",
    "        continue\n",
    "    if len(seq)>400:continue\n",
    "    CoM = torch.mean(frames.flatten(end_dim=-2),dim=-2, keepdim=True)\n",
    "    frames = frames - CoM[None,:]\n",
    "    frames = frames/data_std\n",
    "    i_seq = data_read.encode(seq)\n",
    "    \n",
    "    pred_h_eps, h_eps, pred_x_eps, x_eps=model(frames, i_seq, edges)\n",
    "\n",
    "    \n",
    "    x_eps = x_eps.to(\"cuda\")\n",
    "    loss = denoising_loss(pred_x_eps,x_eps)\n",
    "    loss.backward()\n",
    "    agg_loss +=loss\n",
    "    if (i+1)%batch_size ==0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if (i+1)%500 == 0:\n",
    "        print(f\"{i+1} Step : {loss}\")\n",
    "        print(f\"{i+1} Step : {agg_loss/500}\")\n",
    "        print(type(agg_loss))\n",
    "        torch.save({\n",
    "            'epoch': i+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'step_loss': agg_loss[0]\n",
    "            }, f'./model_weights/prot_eGNN_{i+1}')\n",
    "        agg_loss = torch.tensor([0.],dtype=torch.float32).to(\"cuda\")\n",
    "        if i>900:\n",
    "            model.eval()\n",
    "            for j in train_list:\n",
    "                v_frames,v_seq,v_edges=input_generation(pdb_dir+j)\n",
    "                del v_frames\n",
    "                del v_edges\n",
    "                gc.collect()\n",
    "                v_i_seq = data_read.encode(v_seq)\n",
    "                with torch.no_grad():\n",
    "                    coords=model.sample(v_i_seq)\n",
    "                    coords=coords*data_std\n",
    "                res = generate_res_object(v_seq,coords)\n",
    "                generate_pdb(g_pdb_dir+f\"pred_{j}_model_{i+1}\",res)  \n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
