{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model for Predicting Molecular coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from dgl.data.utils import split_dataset\n",
    "from dgl.data import QM9EdgeDataset\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from e3nn import o3\n",
    "from e3nn.o3 import FullyConnectedTensorProduct\n",
    "from e3nn.nn import Gate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load the data from DGL. Using QM9EdgeDataset as we are only using the 3D coordinates and the sequence attributes.\n",
    "\n",
    "- Todo: split the data into train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n",
      "{'pos': tensor([[-1.2700e-02,  1.0858e+00,  8.0000e-03],\n",
      "        [ 2.2000e-03, -6.0000e-03,  2.0000e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  3.0000e-04],\n",
      "        [-5.4080e-01,  1.4475e+00, -8.7660e-01],\n",
      "        [-5.2380e-01,  1.4379e+00,  9.0640e-01]]), 'attr': tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 4.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])}\n",
      "130831\n"
     ]
    }
   ],
   "source": [
    "qm9_data = QM9EdgeDataset()\n",
    "print(qm9_data[0][0].ndata)\n",
    "print(len(qm9_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset to get graphs, node features, edge features, and 3D coordinates\n",
    "def process_qm9_data(data):\n",
    "    graphs, node_features, coordinates = [], [], []\n",
    "    for i in range(len(data)):\n",
    "        g = data[i][0]  # DGLGraph for the molecule\n",
    "        coords = g.ndata['pos']  # 3D coordinates of atoms\n",
    "        \n",
    "        # Append graph and features\n",
    "        graphs.append(g)\n",
    "        node_features.append(g.ndata['attr'])\n",
    "        coordinates.append(coords)\n",
    "    \n",
    "    return graphs, node_features, coordinates\n",
    "\n",
    "graphs, node_features, coordinates = process_qm9_data(qm9_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 4.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(node_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom collate function to handle DGLGraphs in the DataLoader\n",
    "def collate_fn(batch):\n",
    "    graphs, node_features, coordinates = map(list, zip(*batch))\n",
    "    \n",
    "    # Batch graphs\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    \n",
    "    # Concatenate node and edge features along the batch dimension\n",
    "    batched_node_features = torch.cat(node_features, dim=0)\n",
    "    batched_coordinates = torch.cat(coordinates, dim=0)\n",
    "    \n",
    "    return batched_graph, batched_node_features, batched_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9Dataset(Dataset):\n",
    "    def __init__(self, graphs, node_features, coordinates):\n",
    "        self.graphs = graphs\n",
    "        self.node_features = node_features\n",
    "        self.coordinates = coordinates\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.graphs[idx], self.node_features[idx], self.coordinates[idx])\n",
    "\n",
    "# Initialize QM9 dataset and DataLoader\n",
    "qm9_dataset = QM9Dataset(graphs, node_features, coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE3EquivariantLayer(nn.Module):\n",
    "    def __init__(self, input_irreps, output_irreps, hidden_dim=128):\n",
    "        \"\"\"\n",
    "        Initialize an SE(3)-equivariant layer.\n",
    "        \n",
    "        Args:\n",
    "            input_irreps (o3.Irreps): Irreducible representations of input features.\n",
    "            output_irreps (o3.Irreps): Irreducible representations of output features.\n",
    "            hidden_dim (int): Hidden dimension of fully connected layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define equivariant fully connected layer\n",
    "        self.fc_tp = FullyConnectedTensorProduct(input_irreps, o3.Irreps(f\"{hidden_dim}x0e\"), output_irreps)\n",
    "        \n",
    "        # Nonlinear activation - gate structure to control outputs\n",
    "        scalar_irreps = o3.Irreps(\"0e\")  # Scalar irreps\n",
    "        self.gate = Gate(scalar_irreps, [nn.SiLU()], output_irreps)\n",
    "\n",
    "    def forward(self, features, edge_vectors):\n",
    "        \"\"\"\n",
    "        Forward pass for SE(3)-equivariant layer.\n",
    "        \n",
    "        Args:\n",
    "            features (torch.Tensor): Input features (node embeddings).\n",
    "            edge_vectors (torch.Tensor): Edge vectors in 3D space, for relative distances.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: SE(3)-equivariant output features.\n",
    "        \"\"\"\n",
    "        # Step 1: Fully connected tensor product\n",
    "        x = self.fc_tp(features, edge_vectors)\n",
    "        \n",
    "        # Step 2: Nonlinearity (gating mechanism)\n",
    "        x = self.gate(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivariantDiffusionProcess(nn.Module):\n",
    "    def __init__(self, timesteps):\n",
    "        super().__init__()\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def forward_diffusion(self, coords, t):\n",
    "        \"\"\"\n",
    "        Forward diffusion process to add noise to 3D coordinates.\n",
    "        \n",
    "        Args:\n",
    "            coords (torch.Tensor): Original coordinates.\n",
    "            t (int): Current timestep.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Noisy coordinates.\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(coords)\n",
    "        alpha_t = torch.exp(-0.5 * t / self.timesteps)  # Scaling factor\n",
    "        noisy_coords = alpha_t * coords + (1 - alpha_t**2).sqrt() * noise\n",
    "        return noisy_coords\n",
    "\n",
    "    def reverse_denoising(self, noisy_coords, predicted_noise, t):\n",
    "        \"\"\"\n",
    "        Reverse diffusion to progressively denoise coordinates.\n",
    "        \n",
    "        Args:\n",
    "            noisy_coords (torch.Tensor): Noisy coordinates at timestep t.\n",
    "            predicted_noise (torch.Tensor): Noise predicted by the model.\n",
    "            t (int): Current timestep.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Partially denoised coordinates.\n",
    "        \"\"\"\n",
    "        alpha_t = torch.exp(-0.5 * t / self.timesteps)\n",
    "        return (noisy_coords - (1 - alpha_t**2).sqrt() * predicted_noise) / alpha_t\n",
    "\n",
    "\n",
    "class EquivariantDiffusionModel(nn.Module):\n",
    "    def __init__(self, node_feat_dim, hidden_dim, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define irreps for input and output features\n",
    "        self.input_irreps = o3.Irreps(f\"{node_feat_dim}x0e\")  # Scalars (atomic numbers, etc.)\n",
    "        print(self.input_irreps)\n",
    "        self.output_irreps = o3.Irreps(\"1x1o\")  # Output irreps as vectors for 3D coordinates\n",
    "        self.hidden_irreps = o3.Irreps(f\"{hidden_dim}x0e + {hidden_dim}x1o\")  # Scalars + vectors\n",
    "\n",
    "        # Create equivariant layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            SE3EquivariantLayer(self.input_irreps, self.hidden_irreps)\n",
    "            for _ in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final layer to predict noise in coordinates\n",
    "        self.final_layer = SE3EquivariantLayer(self.hidden_irreps, self.output_irreps)\n",
    "\n",
    "    def forward(self, g, node_features, noisy_coords):\n",
    "        \"\"\"\n",
    "        Forward pass for the diffusion model.\n",
    "\n",
    "        Args:\n",
    "            g (DGLGraph): Graph structure.\n",
    "            node_features (torch.Tensor): Node features for each atom.\n",
    "            noisy_coords (torch.Tensor): Noisy 3D coordinates.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted noise for denoising.\n",
    "        \"\"\"\n",
    "        x = node_features\n",
    "        edge_vectors = noisy_coords[g.edges()[1]] - noisy_coords[g.edges()[0]]  # Relative positions\n",
    "        \n",
    "        # Pass through equivariant layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_vectors)\n",
    "\n",
    "        # Final prediction for noise\n",
    "        predicted_noise = self.final_layer(x, edge_vectors)\n",
    "        return predicted_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100        # Number of epochs\n",
    "batch_size = 16     # Batch size\n",
    "learning_rate = 1e-4  # Learning rate\n",
    "\n",
    "dataset_size = len(qm9_dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% for training\n",
    "val_size = int(0.1 * dataset_size)    # 10% for validation\n",
    "test_size = dataset_size - train_size - val_size  # Remaining 10% for test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(qm9_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11x0e\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'act_gates' and 'irreps_gated'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      4\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEquivariantDiffusionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feat_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_feat_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m diffusion_process \u001b[38;5;241m=\u001b[39m EquivariantDiffusionProcess(timesteps\u001b[38;5;241m=\u001b[39mtimesteps)\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[48], line 50\u001b[0m, in \u001b[0;36mEquivariantDiffusionModel.__init__\u001b[0;34m(self, node_feat_dim, hidden_dim, num_layers)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_irreps \u001b[38;5;241m=\u001b[39m o3\u001b[38;5;241m.\u001b[39mIrreps(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx0e + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx1o\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Scalars + vectors\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Create equivariant layers\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m     51\u001b[0m     SE3EquivariantLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_irreps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_irreps)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers)\n\u001b[1;32m     53\u001b[0m ])\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Final layer to predict noise in coordinates\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer \u001b[38;5;241m=\u001b[39m SE3EquivariantLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_irreps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_irreps)\n",
      "Cell \u001b[0;32mIn[48], line 51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_irreps \u001b[38;5;241m=\u001b[39m o3\u001b[38;5;241m.\u001b[39mIrreps(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx0e + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx1o\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Scalars + vectors\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Create equivariant layers\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mSE3EquivariantLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_irreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_irreps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers)\n\u001b[1;32m     53\u001b[0m ])\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Final layer to predict noise in coordinates\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer \u001b[38;5;241m=\u001b[39m SE3EquivariantLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_irreps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_irreps)\n",
      "Cell \u001b[0;32mIn[45], line 18\u001b[0m, in \u001b[0;36mSE3EquivariantLayer.__init__\u001b[0;34m(self, input_irreps, output_irreps, hidden_dim)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Nonlinear activation - gate structure to control outputs\u001b[39;00m\n\u001b[1;32m     17\u001b[0m scalar_irreps \u001b[38;5;241m=\u001b[39m o3\u001b[38;5;241m.\u001b[39mIrreps(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0e\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Scalar irreps\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate \u001b[38;5;241m=\u001b[39m \u001b[43mGate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalar_irreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSiLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_irreps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'act_gates' and 'irreps_gated'"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and diffusion process\n",
    "node_feat_dim = 11  # Adjust based on dataset\n",
    "hidden_dim = 128\n",
    "timesteps = 1000\n",
    "model = EquivariantDiffusionModel(node_feat_dim=node_feat_dim, hidden_dim=hidden_dim)\n",
    "diffusion_process = EquivariantDiffusionProcess(timesteps=timesteps)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0:\n",
      "Epoch 1/100, Loss: 2.970868894974415\n",
      "Epoch 1/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 1:\n",
      "Epoch 2/100, Loss: 2.9705692175439795\n",
      "Epoch 2/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 2:\n",
      "Epoch 3/100, Loss: 2.9706233970909737\n",
      "Epoch 3/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 3:\n",
      "Epoch 4/100, Loss: 2.970562763477968\n",
      "Epoch 4/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 4:\n",
      "Epoch 5/100, Loss: 2.9706947670111195\n",
      "Epoch 5/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 5:\n",
      "Epoch 6/100, Loss: 2.9707352902611546\n",
      "Epoch 6/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 6:\n",
      "Epoch 7/100, Loss: 2.9707057800033487\n",
      "Epoch 7/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 7:\n",
      "Epoch 8/100, Loss: 2.970980544332261\n",
      "Epoch 8/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 8:\n",
      "Epoch 9/100, Loss: 2.970757808535152\n",
      "Epoch 9/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 9:\n",
      "Epoch 10/100, Loss: 2.97076145066868\n",
      "Epoch 10/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 10:\n",
      "Epoch 11/100, Loss: 2.970628232629392\n",
      "Epoch 11/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 11:\n",
      "Epoch 12/100, Loss: 2.97092980603784\n",
      "Epoch 12/100, Validation Loss: 2.9605988322376913\n",
      "Train epoch 12:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m noisy_coords \u001b[38;5;241m=\u001b[39m noisy_coords\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Predict the denoised coordinates from the noisy ones\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m denoised_features, denoised_coords \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate the loss as the mean squared error between predicted and actual noise\u001b[39;00m\n\u001b[1;32m     32\u001b[0m noise \u001b[38;5;241m=\u001b[39m noisy_coords \u001b[38;5;241m-\u001b[39m true_coords  \u001b[38;5;66;03m# Calculate actual noise added\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 25\u001b[0m, in \u001b[0;36mEquivariantDiffusionModel.forward\u001b[0;34m(self, g, node_features, coords)\u001b[0m\n\u001b[1;32m     22\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_encoder(node_features))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m equiv_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mequiv_layers:\n\u001b[0;32m---> 25\u001b[0m     h, coords \u001b[38;5;241m=\u001b[39m \u001b[43mequiv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Decode to original feature dimension\u001b[39;00m\n\u001b[1;32m     28\u001b[0m denoised_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_decoder(h)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m, in \u001b[0;36mEquivariantLayer.forward\u001b[0;34m(self, g, features, coords)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, features, coords):\n\u001b[0;32m----> 8\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# apply graph convolution\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Apply transformations on coordinates for equivariance if needed\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h, coords\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py:460\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    458\u001b[0m     rst \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mdstdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m         rst \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_norm \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    463\u001b[0m     degs \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39min_degrees()\u001b[38;5;241m.\u001b[39mto(feat_dst)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Train epoch {epoch}:\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        g, node_features, true_coords = batch  # Unpack batch (graph, features, coordinates)\n",
    "        \n",
    "        # Ensure node features and true_coords have requires_grad=True\n",
    "        node_features = node_features.requires_grad_(True)\n",
    "        true_coords = true_coords.requires_grad_(True)\n",
    "        # Sample a random timestep t\n",
    "        t = torch.randint(0, diffusion_process.timesteps, (1,)).item()\n",
    "\n",
    "        # Add noise to the true coordinates (forward diffusion process)\n",
    "        noisy_coords = diffusion_process.forward_diffusion(true_coords, t)\n",
    "        noisy_coords = noisy_coords.requires_grad_(True)\n",
    "        \n",
    "        # Predict the denoised coordinates from the noisy ones\n",
    "        denoised_features, denoised_coords = model(g, node_features, noisy_coords)\n",
    "        \n",
    "        # Calculate the loss as the mean squared error between predicted and actual noise\n",
    "        noise = noisy_coords - true_coords  # Calculate actual noise added\n",
    "        loss = F.mse_loss(denoised_coords, noise)  # Denoising loss\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "    \n",
    "    # validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            g, node_features, true_coords = batch\n",
    "            \n",
    "            # Sample a random timestep t for validation\n",
    "            t = torch.randint(0, diffusion_process.timesteps, (1,)).item()\n",
    "\n",
    "            noisy_coords = diffusion_process.forward_diffusion(true_coords, t)\n",
    "            denoised_features, denoised_coords = model(g, node_features, noisy_coords)\n",
    "\n",
    "            noise = noisy_coords - true_coords\n",
    "            val_loss += F.mse_loss(denoised_coords, noise).item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the equivariant layer (you might need a custom SE(3)-equivariant layer or use an existing library for SE(3) equivariance)\n",
    "# class EquivariantLayer(nn.Module):\n",
    "#     def __init__(self, in_dim, out_dim):\n",
    "#         super(EquivariantLayer, self).__init__()\n",
    "#         self.layer = dglnn.GraphConv(in_dim, out_dim)  # Placeholder, should be SE(3) equivariant\n",
    "        \n",
    "#     def forward(self, g, features, coords):\n",
    "#         h = self.layer(g, features)  # apply graph convolution\n",
    "#         # Apply transformations on coordinates for equivariance if needed\n",
    "#         return h, coords\n",
    "\n",
    "# # Define the Denoising Model\n",
    "# class EquivariantDiffusionModel(nn.Module):\n",
    "#     def __init__(self, node_feat_dim, hidden_dim):\n",
    "#         super(EquivariantDiffusionModel, self).__init__()\n",
    "#         self.node_encoder = nn.Linear(node_feat_dim, hidden_dim)\n",
    "#         self.equiv_layers = nn.ModuleList([EquivariantLayer(hidden_dim, hidden_dim) for _ in range(3)])\n",
    "#         self.node_decoder = nn.Linear(hidden_dim, node_feat_dim)\n",
    "    \n",
    "#     def forward(self, g, node_features, coords):\n",
    "#         # Encode node and edge features\n",
    "#         h = F.relu(self.node_encoder(node_features))\n",
    "        \n",
    "#         for equiv_layer in self.equiv_layers:\n",
    "#             h, coords = equiv_layer(g, h, coords)\n",
    "        \n",
    "#         # Decode to original feature dimension\n",
    "#         denoised_features = self.node_decoder(h)\n",
    "#         return denoised_features, coords\n",
    "\n",
    "# # Sample Diffusion Process for 3D Denoising\n",
    "# class DiffusionProcess:\n",
    "#     def __init__(self, timesteps, beta_start=0.0001, beta_end=0.02):\n",
    "#         self.timesteps = timesteps\n",
    "#         self.beta = torch.linspace(beta_start, beta_end, timesteps)\n",
    "    \n",
    "#     def forward_diffusion(self, coords, t):\n",
    "#         noise = torch.randn_like(coords)\n",
    "#         return coords * (1 - self.beta[t]).sqrt() + noise * self.beta[t].sqrt()\n",
    "    \n",
    "#     def reverse_denoising(self, model, g, features, coords, t):\n",
    "#         denoised_features, denoised_coords = model(g, features, coords)\n",
    "#         # Implement denoising step based on learned prediction and noise schedule\n",
    "#         return denoised_coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
