{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EquivariantLayer(nn.Module):\n",
    "#     def __init__(self, in_dim, out_dim):\n",
    "#         super(EquivariantLayer, self).__init__()\n",
    "#         self.layer = dglnn.GraphConv(in_dim, out_dim)  # Placeholder, should be SE(3) equivariant\n",
    "        \n",
    "#     def forward(self, g, features, coords):\n",
    "#         h = self.layer(g, features)  # apply graph convolution\n",
    "#         # Apply transformations on coordinates for equivariance if needed\n",
    "#         return h, coords\n",
    "    \n",
    "class EquivariantLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EquivariantLayer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.coord_linear = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, g, features, coordinates):\n",
    "        # Apply linear transformation to node features\n",
    "        h = self.linear(features)\n",
    "        \n",
    "        # Calculate messages with equivariance: update coordinates based on node features\n",
    "        g.ndata['h'] = h\n",
    "        g.ndata['coord'] = coordinates\n",
    "        g.update_all(fn.copy_u('coord', 'm'), fn.mean('m', 'h_coord'))\n",
    "        \n",
    "        # Update node coordinates\n",
    "        coord_updates = self.coord_linear(g.ndata['h_coord'])\n",
    "        new_coordinates = coordinates + coord_updates\n",
    "\n",
    "        return h, new_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Denoising Model\n",
    "# class EquivariantDiffusionModel(nn.Module):\n",
    "#     def __init__(self, node_feat_dim, hidden_dim):\n",
    "#         super(EquivariantDiffusionModel, self).__init__()\n",
    "#         self.node_encoder = nn.Linear(node_feat_dim, hidden_dim)\n",
    "#         self.equiv_layers = nn.ModuleList([EquivariantLayer(hidden_dim, hidden_dim) for _ in range(3)])\n",
    "#         self.node_decoder = nn.Linear(hidden_dim, node_feat_dim)\n",
    "    \n",
    "#     def forward(self, g, node_features, coords):\n",
    "#         # Encode node\n",
    "#         h = F.relu(self.node_encoder(node_features))        \n",
    "#         for equiv_layer in self.equiv_layers:\n",
    "#             h, coords = equiv_layer(g, h, coords)\n",
    "        \n",
    "#         # Decode to original feature dimension\n",
    "#         denoised_features = self.node_decoder(h)\n",
    "#         return denoised_features, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivariantDiffusionModel(nn.Module):\n",
    "    def __init__(self, node_feat_dim, hidden_dim, num_layers=3):\n",
    "        super(EquivariantDiffusionModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim # 128\n",
    "\n",
    "        # Initial linear layer for node features\n",
    "        self.input_layer = nn.Linear(node_feat_dim, hidden_dim) # 11, 128\n",
    "\n",
    "        # Define multiple equivariant layers\n",
    "        self.equiv_layers = nn.ModuleList([\n",
    "            EquivariantLayer(hidden_dim, hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Output layers for final features and coordinates\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)  # For final prediction\n",
    "\n",
    "    def forward(self, g, node_features, coordinates):\n",
    "        print(\"this is the g, node_feature, coordinates shape\")\n",
    "        print(g)\n",
    "        print(node_features.shape)\n",
    "        print(coordinates.shape)\n",
    "        # Initial feature transformation\n",
    "        h = F.relu(self.input_layer(node_features))\n",
    "\n",
    "        # Forward pass through equivariant layers\n",
    "        for i in range(self.num_layers):\n",
    "            h, coordinates = self.equiv_layers[i](g, h, coordinates)\n",
    "\n",
    "        # Final prediction\n",
    "        pred = self.output_layer(h)\n",
    "\n",
    "        return pred, coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Diffusion Process for 3D Denoising\n",
    "class DiffusionProcess:\n",
    "    def __init__(self, timesteps, beta_start=0.0001, beta_end=0.02):\n",
    "        self.timesteps = timesteps\n",
    "        self.beta = torch.linspace(beta_start, beta_end, timesteps)\n",
    "    \n",
    "    def forward_diffusion(self, coords, t):\n",
    "        noise = torch.randn_like(coords)\n",
    "        return coords * (1 - self.beta[t]).sqrt() + noise * self.beta[t].sqrt()\n",
    "    \n",
    "    def reverse_denoising(self, model, g, features, coords, t):\n",
    "        denoised_features, denoised_coords = model(g, features, coords)\n",
    "        # Implement denoising step based on learned prediction and noise schedule\n",
    "        return denoised_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "from dgl.data import QM9\n",
    "\n",
    "# Load QM9 dataset\n",
    "qm9_data = QM9(label_keys=['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve'])\n",
    "\n",
    "# Preprocess dataset to get graphs, node features, edge features, and 3D coordinates\n",
    "def process_qm9_data(data):\n",
    "    graphs, node_features, coordinates = [], [], []\n",
    "    for i in range(10):\n",
    "        g = data[i][0]  # DGLGraph for the molecule\n",
    "        coords = g.ndata['R']  # 3D coordinates of atoms\n",
    "        \n",
    "        # Append graph and features\n",
    "        graphs.append(g)\n",
    "        node_features.append(g.ndata['Z'])\n",
    "        coordinates.append(coords)\n",
    "    \n",
    "    return graphs, node_features, coordinates\n",
    "\n",
    "graphs, node_features, coordinates = process_qm9_data(qm9_data)\n",
    "print(node_features[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 1, 1, 1])\n",
      "tensor([6, 1, 1, 1, 1])\n",
      "tensor([[-1.2698e-02,  1.0858e+00,  8.0010e-03],\n",
      "        [ 2.1504e-03, -6.0313e-03,  1.9761e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  2.7657e-04],\n",
      "        [-5.4082e-01,  1.4475e+00, -8.7664e-01],\n",
      "        [-5.2381e-01,  1.4379e+00,  9.0640e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0].ndata['Z'])\n",
    "print(node_features[0])\n",
    "print(coordinates[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QM9Dataset(Dataset):\n",
    "    def __init__(self, graphs, node_features, coordinates):\n",
    "        self.graphs = graphs\n",
    "        self.node_features = node_features\n",
    "        self.coordinates = coordinates\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.graphs[idx], self.node_features[idx], self.coordinates[idx])\n",
    "\n",
    "# Initialize QM9 dataset and DataLoader\n",
    "qm9_dataset = QM9Dataset(graphs, node_features, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(qm9_dataset[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "# Custom collate function to handle DGLGraphs in the DataLoader\n",
    "def collate_fn(batch):\n",
    "    graphs, node_features, coordinates = map(list, zip(*batch))\n",
    "    print(\"before cat: ==========>\")\n",
    "    print(node_features)\n",
    "    \n",
    "    for i, (g, n_feat, coord) in enumerate(zip(graphs, node_features, coordinates)):\n",
    "        print(f\"Graph {i} - Num nodes: {g.number_of_nodes()}\")\n",
    "        print(f\"Node feature shape: {n_feat.shape}\")\n",
    "        print(f\"Coordinate shape: {coord.shape}\")\n",
    "    \n",
    "    # Batch graphs\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    \n",
    "    # Concatenate node and edge features along the batch dimension\n",
    "    batched_node_features = torch.cat(node_features, dim=0).float()\n",
    "    batched_coordinates = torch.cat(coordinates, dim=0).float()\n",
    "    print(\"Hellooo ------>\")\n",
    "    print(batched_node_features)\n",
    "    \n",
    "    print(\"this is the batch_coordinates\")\n",
    "    print(batched_coordinates)\n",
    "    \n",
    "    \n",
    "    return batched_graph, batched_node_features, batched_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming `qm9_dataset` is your custom Dataset\n",
    "dataloader = DataLoader(qm9_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cat: ==========>\n",
      "[tensor([6, 6, 1, 1, 1, 1, 1, 1]), tensor([6, 6, 1, 1])]\n",
      "Graph 0 - Num nodes: 8\n",
      "Node feature shape: torch.Size([8])\n",
      "Coordinate shape: torch.Size([8, 3])\n",
      "Graph 1 - Num nodes: 4\n",
      "Node feature shape: torch.Size([4])\n",
      "Coordinate shape: torch.Size([4, 3])\n",
      "Hellooo ------>\n",
      "tensor([6., 6., 1., 1., 1., 1., 1., 1., 6., 6., 1., 1.])\n",
      "this is the batch_coordinates\n",
      "tensor([[-0.0187,  1.5256,  0.0104],\n",
      "        [ 0.0021, -0.0039,  0.0020],\n",
      "        [ 0.9949,  1.9397,  0.0029],\n",
      "        [-0.5421,  1.9236, -0.8651],\n",
      "        [-0.5252,  1.9142,  0.9000],\n",
      "        [ 0.5255, -0.4019,  0.8775],\n",
      "        [-1.0115, -0.4180,  0.0095],\n",
      "        [ 0.5086, -0.3925, -0.8876],\n",
      "        [ 0.5995,  0.0000,  1.0000],\n",
      "        [-0.5995,  0.0000,  1.0000],\n",
      "        [-1.6616,  0.0000,  1.0000],\n",
      "        [ 1.6616,  0.0000,  1.0000]])\n",
      "this is the g, node_feature, coordinates shape\n",
      "Graph(num_nodes=12, num_edges=68,\n",
      "      ndata_schemes={'R': Scheme(shape=(3,), dtype=torch.float32), 'Z': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "torch.Size([12])\n",
      "torch.Size([12, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x12 and 11x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m noisy_coords \u001b[38;5;241m=\u001b[39m diffusion_process\u001b[38;5;241m.\u001b[39mforward_diffusion(true_coords, t)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Predict the denoised coordinates from the noisy ones\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m denoised_features, denoised_coords \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Calculate the loss as the mean squared error between predicted and actual noise\u001b[39;00m\n\u001b[1;32m     38\u001b[0m noise \u001b[38;5;241m=\u001b[39m noisy_coords \u001b[38;5;241m-\u001b[39m true_coords  \u001b[38;5;66;03m# Calculate actual noise added\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[152], line 24\u001b[0m, in \u001b[0;36mEquivariantDiffusionModel.forward\u001b[0;34m(self, g, node_features, coordinates)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(coordinates\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initial feature transformation\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass through equivariant layers\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_course/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x12 and 11x128)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming the following are already defined:\n",
    "# - `EquivariantDiffusionModel`: the model class for denoising.\n",
    "# - `DiffusionProcess`: the diffusion process class with forward and reverse diffusion methods.\n",
    "# - `molecule_dataset`: a dataset of molecular graphs, with nodes (atoms), edges (bonds), and coordinates.\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100        # Number of epochs\n",
    "batch_size = 16     # Batch size\n",
    "learning_rate = 1e-4  # Learning rate\n",
    "\n",
    "# Initialize model, diffusion process, and optimizer\n",
    "model = EquivariantDiffusionModel(node_feat_dim=11, hidden_dim=128)\n",
    "diffusion_process = DiffusionProcess(timesteps=1000)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        g, node_features, true_coords = batch  # Unpack batch (graph, features, coordinates)\n",
    "\n",
    "        # Sample a random timestep t\n",
    "        t = torch.randint(0, diffusion_process.timesteps, (1,)).item()\n",
    "\n",
    "        # Add noise to the true coordinates (forward diffusion process)\n",
    "        noisy_coords = diffusion_process.forward_diffusion(true_coords, t)\n",
    "        \n",
    "        # Predict the denoised coordinates from the noisy ones\n",
    "        denoised_features, denoised_coords = model(g, node_features, noisy_coords)\n",
    "        \n",
    "        # Calculate the loss as the mean squared error between predicted and actual noise\n",
    "        noise = noisy_coords - true_coords  # Calculate actual noise added\n",
    "        loss = F.mse_loss(denoised_coords, noisy_coords - noise)  # Denoising loss\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
