{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g51Ret2ED5J5",
        "outputId": "9d36a179-e526-4290-e8dc-54505309a416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu5IWGkCGONf",
        "outputId": "2bce21cc-2434-4364-9d2e-c6783ddbf16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CS5284 Project/protein-coordinates/notebooks\n"
          ]
        }
      ],
      "source": [
        "# cd /content/drive/MyDrive/CS5284\\ Project/protein-coordinates/notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d2az6NjFKbU",
        "outputId": "db8a6fcb-205e-4ed5-dc53-0f60aef5752f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Collecting dgl\n",
            "  Using cached dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (553 bytes)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.36.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.84)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl)\n",
            "  Using cached torchdata-0.9.0-cp310-cp310-manylinux1_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel)\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (24.0.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchvision) (3.0.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n",
            "Using cached dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "Using cached torchdata-0.9.0-cp310-cp310-manylinux1_x86_64.whl (2.7 MB)\n",
            "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Building wheels for collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install pytorch matplotlib pandas seaborn scikit-learn torchvision numpy scipy dgl imageio biopython ipykernel ipywidgets wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NIhF7m8F-OX",
        "outputId": "c3ffc80e-c988-4a01-92c2-95604f883e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "  Using cached biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Using cached biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.84\n"
          ]
        }
      ],
      "source": [
        "# pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tb-hgVxWGjJi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9IKBD7KjDxHF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from Bio.PDB import PDBList, PDBParser\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from data_read import *\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from torch.utils.data import DataLoader\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVVuE8-ADxHH"
      },
      "source": [
        "### Data Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QyxvHee-DxHH"
      },
      "outputs": [],
      "source": [
        "def download_pdb_files(sample_size=100):\n",
        "    \"\"\"\n",
        "    Retrieves all PDB IDs available in the PDB.\n",
        "\n",
        "    Returns:\n",
        "        list: List of all PDB IDs.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    pdbl = PDBList()\n",
        "    pdb_ids = pdbl.get_all_entries()\n",
        "    sampled_pdb_ids = np.random.choice(pdb_ids, sample_size, replace=False)\n",
        "    for pdb_id in sampled_pdb_ids:\n",
        "        pdbl.retrieve_pdb_file(pdb_id, pdir='pdb_files', file_format='pdb')\n",
        "    print(f\"Downloaded {len(sampled_pdb_ids)} PDB files.\")\n",
        "    return pdb_ids\n",
        "\n",
        "# download_pdb_files(sample_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BLs7toDzDxHI"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Define the paths\n",
        "# data_path = '../data/pdb_files/'\n",
        "# train_path = os.path.join(data_path, 'train')\n",
        "# test_path = os.path.join(data_path, 'test')\n",
        "\n",
        "# # Create train and test directories if they don't exist\n",
        "# os.makedirs(train_path, exist_ok=True)\n",
        "# os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "# # Get list of all files in the data_path\n",
        "# all_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
        "\n",
        "# # Split the files into train and test sets\n",
        "# train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Move the files to the respective directories\n",
        "# for file in train_files:\n",
        "#     shutil.move(os.path.join(data_path, file), os.path.join(train_path, file))\n",
        "\n",
        "# for file in test_files:\n",
        "#     shutil.move(os.path.join(data_path, file), os.path.join(test_path, file))\n",
        "\n",
        "# print(f\"Moved {len(train_files)} files to {train_path}\")\n",
        "# print(f\"Moved {len(test_files)} files to {test_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIXNpZH9DxHI"
      },
      "source": [
        "### Testing of Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x2Qn9oidDxHI"
      },
      "outputs": [],
      "source": [
        "from src.dataset.datasets import *\n",
        "from src.dataset.transforms import *\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aPSRp55QDxHI"
      },
      "outputs": [],
      "source": [
        "# pdb_transforms = transforms.Compose([NormalizeCoordinates(), PadDatasetTransform(1000)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMreAg8RDxHI",
        "outputId": "296f8344-803b-4de2-c39a-5ce1aaf71824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 77/77 [00:04<00:00, 15.81it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 23.01it/s]\n"
          ]
        }
      ],
      "source": [
        "train_data_path = '../data/pdb_files/train'\n",
        "test_data_path = '../data/pdb_files/test'\n",
        "train_dataset = PDBDataset(train_data_path)\n",
        "if len(train_dataset)%2 != 0:\n",
        "    train_dataset = train_dataset[:-1]\n",
        "test_dataset = PDBDataset(test_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UTIxkrzDxHI"
      },
      "source": [
        "### Data Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EusCes0DxHJ",
        "outputId": "24243668-18f0-429d-95a9-db4c1f4d551e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i_seq count dictionary: {1: 1314, 2: 268, 3: 1036, 4: 1017, 5: 695, 6: 1241, 7: 359, 8: 1058, 9: 1029, 10: 1534, 11: 328, 12: 744, 13: 808, 14: 623, 15: 791, 16: 981, 17: 1031, 18: 1244, 19: 207, 20: 603}\n",
            "Maximum number of nodes in a sample: 773\n",
            "Node count dictionary: {364: 1, 452: 1, 114: 2, 152: 1, 294: 1, 16: 1, 119: 1, 207: 1, 113: 1, 88: 1, 124: 1, 303: 1, 78: 3, 121: 1, 306: 1, 296: 2, 183: 1, 321: 1, 319: 1, 396: 1, 62: 1, 74: 1, 368: 1, 391: 1, 107: 1, 153: 1, 400: 1, 369: 1, 394: 1, 224: 1, 58: 2, 130: 1, 309: 1, 297: 1, 73: 1, 128: 1, 216: 1, 330: 1, 215: 1, 338: 1, 438: 1, 198: 1, 553: 1, 325: 1, 268: 1, 410: 1, 284: 1, 175: 1, 277: 1, 127: 1, 354: 1, 168: 1, 12: 1, 607: 1, 63: 1, 773: 1, 300: 1, 169: 1, 254: 1, 527: 1, 305: 1, 343: 1, 355: 1}\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Initialize a dictionary to store the count of samples with each number of nodes\n",
        "node_count_dict = defaultdict(int)\n",
        "\n",
        "# Enumerate through the train_dataset and count the number of nodes in each sample\n",
        "max_nodes = 0\n",
        "for sample in train_dataset:\n",
        "    num_nodes = sample['positions'].shape[0]\n",
        "    node_count_dict[num_nodes] += 1\n",
        "    if num_nodes > max_nodes:\n",
        "        max_nodes = num_nodes\n",
        "\n",
        "# Initialize a dictionary to store the count of occurrences for each unique value in [\"i_seq\"]\n",
        "i_seq_count_dict = defaultdict(int)\n",
        "\n",
        "# Enumerate through the train_dataset and count the occurrences of each unique value in [\"i_seq\"]\n",
        "for sample in train_dataset:\n",
        "    for i_seq_value in sample['i_seq']:\n",
        "        if i_seq_value != 0:\n",
        "            i_seq_count_dict[i_seq_value.item()] += 1\n",
        "\n",
        "# Sort the keys of i_seq_count_dict\n",
        "i_seq_count_dict = dict(sorted(i_seq_count_dict.items()))\n",
        "\n",
        "print(\"i_seq count dictionary:\", dict(i_seq_count_dict))\n",
        "\n",
        "print(f\"Maximum number of nodes in a sample: {max_nodes}\")\n",
        "print(\"Node count dictionary:\", dict(node_count_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dq2-QueFDxHJ"
      },
      "outputs": [],
      "source": [
        "# Get dataset info required to generate node distribution\n",
        "aa_rep = \"ACDEFGHIKLMNPQRSTVWYBXZJUO\"\n",
        "aa_to_int = {c: i for i, c in enumerate(aa_rep)}\n",
        "\n",
        "dataset_info = {\n",
        "    'name': 'pdb',\n",
        "    'max_n_nodes': max_nodes,\n",
        "    'n_nodes': node_count_dict,\n",
        "    'atom_types': i_seq_count_dict,\n",
        "    'atom_encoder': aa_to_int,\n",
        "    'atom_decoder': [i for i in aa_rep],\n",
        "    'colors_dic': ['C'+str(i) for i in range(len(aa_rep))],\n",
        "    'radius_dic': [0.3]*len(aa_rep)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_VBfshKPDxHJ"
      },
      "outputs": [],
      "source": [
        "from src.dataset.collate import PreprocessPDB\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=PreprocessPDB().collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=PreprocessPDB().collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB5WuEdUDxHJ"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YkGscrN4DxHJ"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Read the jer_config.yml file\n",
        "with open('../edm_config.yml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "class Config:\n",
        "    def __init__(self, config_dict):\n",
        "        for key, value in config_dict.items():\n",
        "            if isinstance(value, str):\n",
        "                try:\n",
        "                    # Try to convert strings to their appropriate types\n",
        "                    value = eval(value)\n",
        "                except:\n",
        "                    pass\n",
        "            setattr(self, key, value)\n",
        "\n",
        "args = Config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QOualQP3DxHJ"
      },
      "outputs": [],
      "source": [
        "from src.models.prepare_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qFbgotIjDxHJ"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyclYtPlDxHJ",
        "outputId": "3438360a-b615-44e7-ffcd-e6b5dfe9b8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropy of n_nodes: H[N] -4.109879493713379\n",
            "alphas2 [9.99990000e-01 9.99982000e-01 9.99958001e-01 9.99918003e-01\n",
            " 9.99862007e-01 9.99790014e-01 9.99702026e-01 9.99598046e-01\n",
            " 9.99478076e-01 9.99342118e-01 9.99190176e-01 9.99022254e-01\n",
            " 9.98838355e-01 9.98638484e-01 9.98422646e-01 9.98190846e-01\n",
            " 9.97943090e-01 9.97679383e-01 9.97399731e-01 9.97104143e-01\n",
            " 9.96792624e-01 9.96465182e-01 9.96121825e-01 9.95762562e-01\n",
            " 9.95387400e-01 9.94996350e-01 9.94589420e-01 9.94166620e-01\n",
            " 9.93727960e-01 9.93273451e-01 9.92803104e-01 9.92316930e-01\n",
            " 9.91814941e-01 9.91297149e-01 9.90763566e-01 9.90214206e-01\n",
            " 9.89649081e-01 9.89068205e-01 9.88471593e-01 9.87859258e-01\n",
            " 9.87231215e-01 9.86587480e-01 9.85928068e-01 9.85252996e-01\n",
            " 9.84562278e-01 9.83855933e-01 9.83133976e-01 9.82396427e-01\n",
            " 9.81643302e-01 9.80874619e-01 9.80090398e-01 9.79290657e-01\n",
            " 9.78475416e-01 9.77644695e-01 9.76798513e-01 9.75936891e-01\n",
            " 9.75059851e-01 9.74167412e-01 9.73259599e-01 9.72336431e-01\n",
            " 9.71397932e-01 9.70444124e-01 9.69475032e-01 9.68490677e-01\n",
            " 9.67491085e-01 9.66476280e-01 9.65446287e-01 9.64401130e-01\n",
            " 9.63340835e-01 9.62265428e-01 9.61174936e-01 9.60069385e-01\n",
            " 9.58948803e-01 9.57813215e-01 9.56662652e-01 9.55497140e-01\n",
            " 9.54316708e-01 9.53121386e-01 9.51911202e-01 9.50686187e-01\n",
            " 9.49446371e-01 9.48191784e-01 9.46922456e-01 9.45638420e-01\n",
            " 9.44339707e-01 9.43026349e-01 9.41698379e-01 9.40355829e-01\n",
            " 9.38998732e-01 9.37627123e-01 9.36241035e-01 9.34840502e-01\n",
            " 9.33425560e-01 9.31996243e-01 9.30552587e-01 9.29094628e-01\n",
            " 9.27622402e-01 9.26135946e-01 9.24635296e-01 9.23120491e-01\n",
            " 9.21591568e-01 9.20048565e-01 9.18491521e-01 9.16920476e-01\n",
            " 9.15335467e-01 9.13736535e-01 9.12123720e-01 9.10497064e-01\n",
            " 9.08856605e-01 9.07202386e-01 9.05534449e-01 9.03852835e-01\n",
            " 9.02157588e-01 9.00448749e-01 8.98726362e-01 8.96990470e-01\n",
            " 8.95241118e-01 8.93478350e-01 8.91702210e-01 8.89912744e-01\n",
            " 8.88109998e-01 8.86294016e-01 8.84464846e-01 8.82622534e-01\n",
            " 8.80767127e-01 8.78898672e-01 8.77017218e-01 8.75122812e-01\n",
            " 8.73215503e-01 8.71295340e-01 8.69362373e-01 8.67416650e-01\n",
            " 8.65458223e-01 8.63487142e-01 8.61503457e-01 8.59507220e-01\n",
            " 8.57498482e-01 8.55477296e-01 8.53443714e-01 8.51397789e-01\n",
            " 8.49339573e-01 8.47269121e-01 8.45186486e-01 8.43091724e-01\n",
            " 8.40984887e-01 8.38866033e-01 8.36735215e-01 8.34592490e-01\n",
            " 8.32437915e-01 8.30271545e-01 8.28093438e-01 8.25903651e-01\n",
            " 8.23702243e-01 8.21489271e-01 8.19264793e-01 8.17028869e-01\n",
            " 8.14781559e-01 8.12522921e-01 8.10253016e-01 8.07971904e-01\n",
            " 8.05679646e-01 8.03376304e-01 8.01061939e-01 7.98736613e-01\n",
            " 7.96400389e-01 7.94053329e-01 7.91695496e-01 7.89326954e-01\n",
            " 7.86947768e-01 7.84558000e-01 7.82157717e-01 7.79746982e-01\n",
            " 7.77325862e-01 7.74894423e-01 7.72452730e-01 7.70000850e-01\n",
            " 7.67538850e-01 7.65066798e-01 7.62584762e-01 7.60092809e-01\n",
            " 7.57591008e-01 7.55079428e-01 7.52558139e-01 7.50027209e-01\n",
            " 7.47486710e-01 7.44936711e-01 7.42377284e-01 7.39808499e-01\n",
            " 7.37230429e-01 7.34643144e-01 7.32046719e-01 7.29441225e-01\n",
            " 7.26826735e-01 7.24203324e-01 7.21571064e-01 7.18930031e-01\n",
            " 7.16280299e-01 7.13621943e-01 7.10955039e-01 7.08279662e-01\n",
            " 7.05595888e-01 7.02903795e-01 7.00203459e-01 6.97494957e-01\n",
            " 6.94778368e-01 6.92053769e-01 6.89321239e-01 6.86580857e-01\n",
            " 6.83832702e-01 6.81076855e-01 6.78313394e-01 6.75542400e-01\n",
            " 6.72763955e-01 6.69978139e-01 6.67185034e-01 6.64384722e-01\n",
            " 6.61577286e-01 6.58762807e-01 6.55941370e-01 6.53113058e-01\n",
            " 6.50277954e-01 6.47436144e-01 6.44587711e-01 6.41732740e-01\n",
            " 6.38871318e-01 6.36003530e-01 6.33129462e-01 6.30249200e-01\n",
            " 6.27362833e-01 6.24470446e-01 6.21572129e-01 6.18667968e-01\n",
            " 6.15758052e-01 6.12842471e-01 6.09921314e-01 6.06994670e-01\n",
            " 6.04062629e-01 6.01125282e-01 5.98182720e-01 5.95235034e-01\n",
            " 5.92282314e-01 5.89324654e-01 5.86362146e-01 5.83394882e-01\n",
            " 5.80422956e-01 5.77446461e-01 5.74465491e-01 5.71480140e-01\n",
            " 5.68490502e-01 5.65496674e-01 5.62498750e-01 5.59496826e-01\n",
            " 5.56490998e-01 5.53481364e-01 5.50468019e-01 5.47451061e-01\n",
            " 5.44430588e-01 5.41406698e-01 5.38379490e-01 5.35349062e-01\n",
            " 5.32315514e-01 5.29278945e-01 5.26239455e-01 5.23197145e-01\n",
            " 5.20152116e-01 5.17104468e-01 5.14054303e-01 5.11001724e-01\n",
            " 5.07946833e-01 5.04889731e-01 5.01830523e-01 4.98769312e-01\n",
            " 4.95706202e-01 4.92641297e-01 4.89574701e-01 4.86506520e-01\n",
            " 4.83436859e-01 4.80365824e-01 4.77293521e-01 4.74220056e-01\n",
            " 4.71145537e-01 4.68070071e-01 4.64993765e-01 4.61916728e-01\n",
            " 4.58839069e-01 4.55760895e-01 4.52682316e-01 4.49603443e-01\n",
            " 4.46524384e-01 4.43445250e-01 4.40366153e-01 4.37287202e-01\n",
            " 4.34208511e-01 4.31130190e-01 4.28052353e-01 4.24975111e-01\n",
            " 4.21898577e-01 4.18822866e-01 4.15748092e-01 4.12674367e-01\n",
            " 4.09601808e-01 4.06530529e-01 4.03460645e-01 4.00392272e-01\n",
            " 3.97325526e-01 3.94260525e-01 3.91197384e-01 3.88136221e-01\n",
            " 3.85077154e-01 3.82020301e-01 3.78965781e-01 3.75913711e-01\n",
            " 3.72864212e-01 3.69817403e-01 3.66773404e-01 3.63732335e-01\n",
            " 3.60694318e-01 3.57659473e-01 3.54627922e-01 3.51599786e-01\n",
            " 3.48575189e-01 3.45554252e-01 3.42537099e-01 3.39523853e-01\n",
            " 3.36514639e-01 3.33509580e-01 3.30508801e-01 3.27512426e-01\n",
            " 3.24520583e-01 3.21533395e-01 3.18550989e-01 3.15573492e-01\n",
            " 3.12601031e-01 3.09633733e-01 3.06671725e-01 3.03715136e-01\n",
            " 3.00764094e-01 2.97818728e-01 2.94879167e-01 2.91945541e-01\n",
            " 2.89017980e-01 2.86096614e-01 2.83181573e-01 2.80272990e-01\n",
            " 2.77370995e-01 2.74475721e-01 2.71587299e-01 2.68705862e-01\n",
            " 2.65831545e-01 2.62964478e-01 2.60104798e-01 2.57252637e-01\n",
            " 2.54408131e-01 2.51571415e-01 2.48742623e-01 2.45921892e-01\n",
            " 2.43109357e-01 2.40305156e-01 2.37509424e-01 2.34722300e-01\n",
            " 2.31943921e-01 2.29174425e-01 2.26413951e-01 2.23662637e-01\n",
            " 2.20920622e-01 2.18188046e-01 2.15465050e-01 2.12751773e-01\n",
            " 2.10048356e-01 2.07354940e-01 2.04671667e-01 2.01998678e-01\n",
            " 1.99336117e-01 1.96684125e-01 1.94042845e-01 1.91412422e-01\n",
            " 1.88792998e-01 1.86184719e-01 1.83587728e-01 1.81002170e-01\n",
            " 1.78428192e-01 1.75865938e-01 1.73315554e-01 1.70777188e-01\n",
            " 1.68250986e-01 1.65737095e-01 1.63235664e-01 1.60746839e-01\n",
            " 1.58270770e-01 1.55807605e-01 1.53357493e-01 1.50920584e-01\n",
            " 1.48497029e-01 1.46086976e-01 1.43690577e-01 1.41307984e-01\n",
            " 1.38939347e-01 1.36584819e-01 1.34244551e-01 1.31918696e-01\n",
            " 1.29607408e-01 1.27310840e-01 1.25029145e-01 1.22762477e-01\n",
            " 1.20510992e-01 1.18274845e-01 1.16054189e-01 1.13849182e-01\n",
            " 1.11659980e-01 1.09486738e-01 1.07329614e-01 1.05188764e-01\n",
            " 1.03064347e-01 1.00956521e-01 9.88654439e-02 9.67912743e-02\n",
            " 9.47341717e-02 9.26942954e-02 9.06718055e-02 8.86668624e-02\n",
            " 8.66796266e-02 8.47102593e-02 8.27589219e-02 8.08257763e-02\n",
            " 7.89109848e-02 7.70147099e-02 7.51371146e-02 7.32783625e-02\n",
            " 7.14386171e-02 6.96180427e-02 6.78168038e-02 6.60350654e-02\n",
            " 6.42729927e-02 6.25307515e-02 6.08085078e-02 5.91064280e-02\n",
            " 5.74246791e-02 5.57634283e-02 5.41228431e-02 5.25030916e-02\n",
            " 5.09043421e-02 4.93267634e-02 4.77705247e-02 4.62357955e-02\n",
            " 4.47227457e-02 4.32315456e-02 4.17623658e-02 4.03153776e-02\n",
            " 3.88907522e-02 3.74886616e-02 3.61092780e-02 3.47527739e-02\n",
            " 3.34193225e-02 3.21090969e-02 3.08222710e-02 2.95590190e-02\n",
            " 2.83195153e-02 2.71039349e-02 2.59124531e-02 2.47452455e-02\n",
            " 2.36024881e-02 2.24843576e-02 2.13910305e-02 2.03226843e-02\n",
            " 1.92794965e-02 1.82616450e-02 1.72693082e-02 1.63026649e-02\n",
            " 1.53618942e-02 1.44471756e-02 1.35586890e-02 1.26966148e-02\n",
            " 1.18611335e-02 1.10524262e-02 1.02706744e-02 9.51605988e-03\n",
            " 8.78876484e-03 8.08897187e-03 7.41686396e-03 6.77262444e-03\n",
            " 6.15643707e-03 5.56848596e-03 5.00895563e-03 4.47803097e-03\n",
            " 3.97589726e-03 3.50274014e-03 3.05874568e-03 2.64410029e-03\n",
            " 2.25899080e-03 1.90360438e-03 1.57812864e-03 1.28275152e-03\n",
            " 1.01766138e-03 7.83046955e-04 5.79097354e-04 4.06002080e-04\n",
            " 2.63951017e-04 1.53134433e-04 7.37429811e-05 2.59676966e-05\n",
            " 1.00159677e-05]\n",
            "gamma [-1.15129155e+01 -1.09251306e+01 -1.00778203e+01 -9.40874268e+00\n",
            " -8.88816710e+00 -8.46825969e+00 -8.11820797e+00 -7.81877150e+00\n",
            " -7.55746608e+00 -7.32582677e+00 -7.11788346e+00 -6.92928201e+00\n",
            " -6.75675569e+00 -6.59779406e+00 -6.45042792e+00 -6.31308514e+00\n",
            " -6.18449116e+00 -6.06359867e+00 -5.94953689e+00 -5.84157408e+00\n",
            " -5.73908957e+00 -5.64155244e+00 -5.54850500e+00 -5.45955000e+00\n",
            " -5.37434042e+00 -5.29257140e+00 -5.21397364e+00 -5.13830814e+00\n",
            " -5.06536178e+00 -4.99494375e+00 -4.92688250e+00 -4.86102331e+00\n",
            " -4.79722608e+00 -4.73536362e+00 -4.67532003e+00 -4.61698950e+00\n",
            " -4.56027508e+00 -4.50508778e+00 -4.45134570e+00 -4.39897331e+00\n",
            " -4.34790077e+00 -4.29806342e+00 -4.24940125e+00 -4.20185848e+00\n",
            " -4.15538317e+00 -4.10992684e+00 -4.06544425e+00 -4.02189301e+00\n",
            " -3.97923346e+00 -3.93742835e+00 -3.89644268e+00 -3.85624355e+00\n",
            " -3.81679995e+00 -3.77808264e+00 -3.74006402e+00 -3.70271801e+00\n",
            " -3.66601992e+00 -3.62994639e+00 -3.59447526e+00 -3.55958551e+00\n",
            " -3.52525717e+00 -3.49147127e+00 -3.45820974e+00 -3.42545540e+00\n",
            " -3.39319187e+00 -3.36140352e+00 -3.33007545e+00 -3.29919341e+00\n",
            " -3.26874381e+00 -3.23871363e+00 -3.20909042e+00 -3.17986224e+00\n",
            " -3.15101768e+00 -3.12254577e+00 -3.09443601e+00 -3.06667831e+00\n",
            " -3.03926297e+00 -3.01218069e+00 -2.98542251e+00 -2.95897981e+00\n",
            " -2.93284431e+00 -2.90700803e+00 -2.88146327e+00 -2.85620263e+00\n",
            " -2.83121894e+00 -2.80650533e+00 -2.78205513e+00 -2.75786192e+00\n",
            " -2.73391949e+00 -2.71022183e+00 -2.68676316e+00 -2.66353786e+00\n",
            " -2.64054050e+00 -2.61776583e+00 -2.59520877e+00 -2.57286439e+00\n",
            " -2.55072792e+00 -2.52879473e+00 -2.50706034e+00 -2.48552039e+00\n",
            " -2.46417067e+00 -2.44300707e+00 -2.42202563e+00 -2.40122247e+00\n",
            " -2.38059385e+00 -2.36013612e+00 -2.33984573e+00 -2.31971924e+00\n",
            " -2.29975330e+00 -2.27994464e+00 -2.26029009e+00 -2.24078657e+00\n",
            " -2.22143107e+00 -2.20222065e+00 -2.18315246e+00 -2.16422373e+00\n",
            " -2.14543174e+00 -2.12677385e+00 -2.10824749e+00 -2.08985013e+00\n",
            " -2.07157934e+00 -2.05343271e+00 -2.03540792e+00 -2.01750268e+00\n",
            " -1.99971476e+00 -1.98204200e+00 -1.96448226e+00 -1.94703347e+00\n",
            " -1.92969361e+00 -1.91246068e+00 -1.89533275e+00 -1.87830792e+00\n",
            " -1.86138434e+00 -1.84456020e+00 -1.82783370e+00 -1.81120312e+00\n",
            " -1.79466676e+00 -1.77822294e+00 -1.76187003e+00 -1.74560644e+00\n",
            " -1.72943060e+00 -1.71334097e+00 -1.69733604e+00 -1.68141435e+00\n",
            " -1.66557444e+00 -1.64981490e+00 -1.63413434e+00 -1.61853138e+00\n",
            " -1.60300470e+00 -1.58755297e+00 -1.57217491e+00 -1.55686925e+00\n",
            " -1.54163474e+00 -1.52647017e+00 -1.51137433e+00 -1.49634605e+00\n",
            " -1.48138416e+00 -1.46648753e+00 -1.45165504e+00 -1.43688559e+00\n",
            " -1.42217810e+00 -1.40753150e+00 -1.39294475e+00 -1.37841681e+00\n",
            " -1.36394669e+00 -1.34953337e+00 -1.33517587e+00 -1.32087324e+00\n",
            " -1.30662452e+00 -1.29242877e+00 -1.27828507e+00 -1.26419252e+00\n",
            " -1.25015021e+00 -1.23615727e+00 -1.22221282e+00 -1.20831600e+00\n",
            " -1.19446598e+00 -1.18066192e+00 -1.16690300e+00 -1.15318840e+00\n",
            " -1.13951732e+00 -1.12588899e+00 -1.11230260e+00 -1.09875741e+00\n",
            " -1.08525264e+00 -1.07178756e+00 -1.05836141e+00 -1.04497347e+00\n",
            " -1.03162301e+00 -1.01830932e+00 -1.00503169e+00 -9.91789438e-01\n",
            " -9.78581858e-01 -9.65408273e-01 -9.52268010e-01 -9.39160402e-01\n",
            " -9.26084788e-01 -9.13040516e-01 -9.00026940e-01 -8.87043420e-01\n",
            " -8.74089323e-01 -8.61164023e-01 -8.48266898e-01 -8.35397335e-01\n",
            " -8.22554723e-01 -8.09738460e-01 -7.96947946e-01 -7.84182591e-01\n",
            " -7.71441804e-01 -7.58725005e-01 -7.46031614e-01 -7.33361059e-01\n",
            " -7.20712771e-01 -7.08086186e-01 -6.95480742e-01 -6.82895885e-01\n",
            " -6.70331063e-01 -6.57785727e-01 -6.45259332e-01 -6.32751339e-01\n",
            " -6.20261210e-01 -6.07788411e-01 -5.95332410e-01 -5.82892681e-01\n",
            " -5.70468700e-01 -5.58059943e-01 -5.45665893e-01 -5.33286033e-01\n",
            " -5.20919850e-01 -5.08566831e-01 -4.96226469e-01 -4.83898256e-01\n",
            " -4.71581688e-01 -4.59276262e-01 -4.46981478e-01 -4.34696836e-01\n",
            " -4.22421840e-01 -4.10155993e-01 -3.97898802e-01 -3.85649773e-01\n",
            " -3.73408415e-01 -3.61174239e-01 -3.48946754e-01 -3.36725473e-01\n",
            " -3.24509907e-01 -3.12299572e-01 -3.00093980e-01 -2.87892646e-01\n",
            " -2.75695086e-01 -2.63500815e-01 -2.51309349e-01 -2.39120204e-01\n",
            " -2.26932897e-01 -2.14746943e-01 -2.02561860e-01 -1.90377161e-01\n",
            " -1.78192365e-01 -1.66006985e-01 -1.53820536e-01 -1.41632534e-01\n",
            " -1.29442490e-01 -1.17249919e-01 -1.05054332e-01 -9.28552399e-02\n",
            " -8.06521526e-02 -6.84445791e-02 -5.62320266e-02 -4.40140013e-02\n",
            " -3.17900077e-02 -1.95595489e-02 -7.32212627e-03  4.92276070e-03\n",
            "  1.71756143e-02  2.94369390e-02  4.17072410e-02  5.39870292e-02\n",
            "  6.62768145e-02  7.85771104e-02  9.08884327e-02  1.03211300e-01\n",
            "  1.15546234e-01  1.27893759e-01  1.40254403e-01  1.52628695e-01\n",
            "  1.65017169e-01  1.77420363e-01  1.89838818e-01  2.02273077e-01\n",
            "  2.14723688e-01  2.27191204e-01  2.39676180e-01  2.52179176e-01\n",
            "  2.64700758e-01  2.77241493e-01  2.89801955e-01  3.02382722e-01\n",
            "  3.14984378e-01  3.27607510e-01  3.40252711e-01  3.52920581e-01\n",
            "  3.65611723e-01  3.78326747e-01  3.91066268e-01  4.03830909e-01\n",
            "  4.16621296e-01  4.29438063e-01  4.42281852e-01  4.55153310e-01\n",
            "  4.68053090e-01  4.80981854e-01  4.93940271e-01  5.06929016e-01\n",
            "  5.19948774e-01  5.33000235e-01  5.46084100e-01  5.59201076e-01\n",
            "  5.72351881e-01  5.85537239e-01  5.98757885e-01  6.12014563e-01\n",
            "  6.25308026e-01  6.38639036e-01  6.52008368e-01  6.65416804e-01\n",
            "  6.78865138e-01  6.92354176e-01  7.05884732e-01  7.19457635e-01\n",
            "  7.33073724e-01  7.46733850e-01  7.60438876e-01  7.74189679e-01\n",
            "  7.87987149e-01  8.01832188e-01  8.15725713e-01  8.29668656e-01\n",
            "  8.43661960e-01  8.57706587e-01  8.71803513e-01  8.85953729e-01\n",
            "  9.00158242e-01  9.14418077e-01  9.28734275e-01  9.43107896e-01\n",
            "  9.57540015e-01  9.72031730e-01  9.86584154e-01  1.00119842e+00\n",
            "  1.01587569e+00  1.03061713e+00  1.04542394e+00  1.06029734e+00\n",
            "  1.07523856e+00  1.09024888e+00  1.10532959e+00  1.12048198e+00\n",
            "  1.13570741e+00  1.15100723e+00  1.16638284e+00  1.18183566e+00\n",
            "  1.19736713e+00  1.21297872e+00  1.22867195e+00  1.24444834e+00\n",
            "  1.26030948e+00  1.27625695e+00  1.29229241e+00  1.30841751e+00\n",
            "  1.32463397e+00  1.34094352e+00  1.35734796e+00  1.37384910e+00\n",
            "  1.39044881e+00  1.40714899e+00  1.42395160e+00  1.44085862e+00\n",
            "  1.45787210e+00  1.47499412e+00  1.49222683e+00  1.50957241e+00\n",
            "  1.52703311e+00  1.54461123e+00  1.56230911e+00  1.58012918e+00\n",
            "  1.59807390e+00  1.61614582e+00  1.63434753e+00  1.65268170e+00\n",
            "  1.67115108e+00  1.68975848e+00  1.70850678e+00  1.72739896e+00\n",
            "  1.74643804e+00  1.76562717e+00  1.78496957e+00  1.80446853e+00\n",
            "  1.82412746e+00  1.84394986e+00  1.86393934e+00  1.88409958e+00\n",
            "  1.90443442e+00  1.92494778e+00  1.94564371e+00  1.96652638e+00\n",
            "  1.98760009e+00  2.00886928e+00  2.03033853e+00  2.05201255e+00\n",
            "  2.07389622e+00  2.09599457e+00  2.11831280e+00  2.14085630e+00\n",
            "  2.16363060e+00  2.18664146e+00  2.20989481e+00  2.23339682e+00\n",
            "  2.25715386e+00  2.28117251e+00  2.30545962e+00  2.33002229e+00\n",
            "  2.35486785e+00  2.38000395e+00  2.40543851e+00  2.43117976e+00\n",
            "  2.45723624e+00  2.48361686e+00  2.51033085e+00  2.53738786e+00\n",
            "  2.56479791e+00  2.59257144e+00  2.62071935e+00  2.64925300e+00\n",
            "  2.67818425e+00  2.70752550e+00  2.73728968e+00  2.76749035e+00\n",
            "  2.79814167e+00  2.82925849e+00  2.86085637e+00  2.89295162e+00\n",
            "  2.92556137e+00  2.95870360e+00  2.99239724e+00  3.02666218e+00\n",
            "  3.06151939e+00  3.09699096e+00  3.13310020e+00  3.16987174e+00\n",
            "  3.20733159e+00  3.24550732e+00  3.28442809e+00  3.32412487e+00\n",
            "  3.36463052e+00  3.40597999e+00  3.44821050e+00  3.49136168e+00\n",
            "  3.53547588e+00  3.58059834e+00  3.62677752e+00  3.67406536e+00\n",
            "  3.72251765e+00  3.77219445e+00  3.82316044e+00  3.87548553e+00\n",
            "  3.92924534e+00  3.98452188e+00  4.04140428e+00  4.09998968e+00\n",
            "  4.16038413e+00  4.22270379e+00  4.28707623e+00  4.35364197e+00\n",
            "  4.42255628e+00  4.49399135e+00  4.56813881e+00  4.64521277e+00\n",
            "  4.72545348e+00  4.80913178e+00  4.89655445e+00  4.98807095e+00\n",
            "  5.08408160e+00  5.18504803e+00  5.29150630e+00  5.40408376e+00\n",
            "  5.52352101e+00  5.65070083e+00  5.78668692e+00  5.93277682e+00\n",
            "  6.09057557e+00  6.26210073e+00  6.44993617e+00  6.65746431e+00\n",
            "  6.88922987e+00  7.15153454e+00  7.45346069e+00  7.80874619e+00\n",
            "  8.23948303e+00  8.78404123e+00  9.51485099e+00  1.05586313e+01\n",
            "  1.15113200e+01]\n"
          ]
        }
      ],
      "source": [
        "model, nodes_dist, prop_dist = get_model(args, device, dataset_info, train_dataloader)\n",
        "optim = get_optim(args, model)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yN4yBAeiDxHK"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tevrXiRUDxHK"
      },
      "outputs": [],
      "source": [
        "from src.train_test import train_epoch, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "6jUk95ruDxHK",
        "outputId": "297088d9-f0b4-4301-a18f-7ba66551a524"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b563c3849c5b4718abf08af7985ae864",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168066200075879, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "CommError",
          "evalue": "Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39monline \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mwandb_usr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mexp_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me3_diffusion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m: args,\n\u001b[1;32m      7\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m'\u001b[39m: wandb\u001b[38;5;241m.\u001b[39mSettings(_disable_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreinit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m----> 8\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1270\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/wandb/analytics/sentry.py:161\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1256\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[1;32m   1255\u001b[0m     wi\u001b[38;5;241m.\u001b[39msetup(kwargs)\n\u001b[0;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:848\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    846\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m--> 848\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
          ]
        }
      ],
      "source": [
        "if args.no_wandb:\n",
        "    mode = 'disabled'\n",
        "else:\n",
        "    wandb.login()\n",
        "    mode = 'online' if args.online else 'offline'\n",
        "    kwargs = {'entity': args.wandb_usr, 'name': args.exp_name, 'project': 'e3_diffusion', 'config': args,\n",
        "          'settings': wandb.Settings(_disable_stats=True), 'reinit': True, 'mode': 'offline'}\n",
        "wandb.init(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fkqjlJn6DxHK"
      },
      "outputs": [],
      "source": [
        "from src.model_utils import Queue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zmQFHlVJDxHK"
      },
      "outputs": [],
      "source": [
        "gradnorm_queue = Queue()\n",
        "gradnorm_queue.add(3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_e8Ou7wIaoMC"
      },
      "outputs": [],
      "source": [
        "# prompt: Get the size of object 'model'\n",
        "\n",
        "# print(f\"Size of model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# print(f\"Allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
        "# print(f\"Reserved memory: {torch.cuda.memory_reserved()} bytes\")\n",
        "# print(f\"Max memory: {torch.cuda.max_memory_allocated()} bytes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oUztWFxKDxHK",
        "outputId": "83edfe35-380f-42bb-e601-8181f9fe0b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x torch.Size([2, 391, 3])\n",
            "h[categorical] torch.Size([2, 391, 26])\n",
            "h[integer] torch.Size([2, 391, 1])\n",
            "Clipped gradient with value inf while allowed 7125.0\n",
            "Epoch: 0, iter: 0/34, Loss 13290213759835439104.00, NLL: 13290213759835439104.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 452, 3])\n",
            "h[categorical] torch.Size([2, 452, 26])\n",
            "h[integer] torch.Size([2, 452, 1])\n",
            "Clipped gradient with value inf while allowed 10722.0\n",
            "Epoch: 0, iter: 1/34, Loss 80332069947825979392.00, NLL: 80332069947825979392.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 296, 3])\n",
            "h[categorical] torch.Size([2, 296, 26])\n",
            "h[integer] torch.Size([2, 296, 1])\n",
            "Clipped gradient with value inf while allowed 15366.9\n",
            "Epoch: 0, iter: 2/34, Loss 725312499032784896.00, NLL: 725312499032784896.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 153, 3])\n",
            "h[categorical] torch.Size([2, 153, 26])\n",
            "h[integer] torch.Size([2, 153, 1])\n",
            "Clipped gradient with value 426305156582211584.0 while allowed 21140.3\n",
            "Epoch: 0, iter: 3/34, Loss 338537912205312.00, NLL: 338537912205312.00, RegTerm: 0.0, GradNorm: 426305156582211584.0\n",
            "x torch.Size([2, 438, 3])\n",
            "h[categorical] torch.Size([2, 438, 26])\n",
            "h[integer] torch.Size([2, 438, 1])\n",
            "Clipped gradient with value inf while allowed 28122.5\n",
            "Epoch: 0, iter: 4/34, Loss 46943895238500941824.00, NLL: 46943895238500941824.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 394, 3])\n",
            "h[categorical] torch.Size([2, 394, 26])\n",
            "h[integer] torch.Size([2, 394, 1])\n",
            "Clipped gradient with value inf while allowed 36391.4\n",
            "Epoch: 0, iter: 5/34, Loss 14340686069501001728.00, NLL: 14340686069501001728.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 338, 3])\n",
            "h[categorical] torch.Size([2, 338, 26])\n",
            "h[integer] torch.Size([2, 338, 1])\n",
            "Clipped gradient with value inf while allowed 46022.6\n",
            "Epoch: 0, iter: 6/34, Loss 239587174285049856.00, NLL: 239587174285049856.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 296, 3])\n",
            "h[categorical] torch.Size([2, 296, 26])\n",
            "h[integer] torch.Size([2, 296, 1])\n",
            "Clipped gradient with value inf while allowed 57088.7\n",
            "Epoch: 0, iter: 7/34, Loss 357369282213969920.00, NLL: 357369282213969920.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 297, 3])\n",
            "h[categorical] torch.Size([2, 297, 26])\n",
            "h[integer] torch.Size([2, 297, 1])\n",
            "Clipped gradient with value inf while allowed 69660.3\n",
            "Epoch: 0, iter: 8/34, Loss 293168145433100288.00, NLL: 293168145433100288.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 175, 3])\n",
            "h[categorical] torch.Size([2, 175, 26])\n",
            "h[integer] torch.Size([2, 175, 1])\n",
            "Clipped gradient with value 278188656714317824.0 while allowed 83805.6\n",
            "Epoch: 0, iter: 9/34, Loss 188736230916096.00, NLL: 188736230916096.00, RegTerm: 0.0, GradNorm: 278188656714317824.0\n",
            "x torch.Size([2, 396, 3])\n",
            "h[categorical] torch.Size([2, 396, 26])\n",
            "h[integer] torch.Size([2, 396, 1])\n",
            "Clipped gradient with value inf while allowed 99591.1\n",
            "Epoch: 0, iter: 10/34, Loss 698970055857143808.00, NLL: 698970055857143808.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 254, 3])\n",
            "h[categorical] torch.Size([2, 254, 26])\n",
            "h[integer] torch.Size([2, 254, 1])\n",
            "Clipped gradient with value inf while allowed 117081.0\n",
            "Epoch: 0, iter: 11/34, Loss 20778940108898304.00, NLL: 20778940108898304.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 607, 3])\n",
            "h[categorical] torch.Size([2, 607, 26])\n",
            "h[integer] torch.Size([2, 607, 1])\n",
            "Clipped gradient with value inf while allowed 136338.3\n",
            "Epoch: 0, iter: 12/34, Loss 186893227270760038400.00, NLL: 186893227270760038400.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 277, 3])\n",
            "h[categorical] torch.Size([2, 277, 26])\n",
            "h[integer] torch.Size([2, 277, 1])\n",
            "Clipped gradient with value inf while allowed 157424.2\n",
            "Epoch: 0, iter: 13/34, Loss 51255297896873984.00, NLL: 51255297896873984.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 303, 3])\n",
            "h[categorical] torch.Size([2, 303, 26])\n",
            "h[integer] torch.Size([2, 303, 1])\n",
            "Clipped gradient with value inf while allowed 180398.4\n",
            "Epoch: 0, iter: 14/34, Loss 100266114604335104.00, NLL: 100266114604335104.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 284, 3])\n",
            "h[categorical] torch.Size([2, 284, 26])\n",
            "h[integer] torch.Size([2, 284, 1])\n",
            "Clipped gradient with value 4391085228110643200.0 while allowed 205319.3\n",
            "Epoch: 0, iter: 15/34, Loss 6961524048396288.00, NLL: 6961524048396288.00, RegTerm: 0.0, GradNorm: 4391085228110643200.0\n",
            "x torch.Size([2, 321, 3])\n",
            "h[categorical] torch.Size([2, 321, 26])\n",
            "h[integer] torch.Size([2, 321, 1])\n",
            "Clipped gradient with value inf while allowed 232244.3\n",
            "Epoch: 0, iter: 16/34, Loss 134264371344834560.00, NLL: 134264371344834560.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 152, 3])\n",
            "h[categorical] torch.Size([2, 152, 26])\n",
            "h[integer] torch.Size([2, 152, 1])\n",
            "Clipped gradient with value 236265515297800192.0 while allowed 261229.4\n",
            "Epoch: 0, iter: 17/34, Loss 225894627016704.00, NLL: 225894627016704.00, RegTerm: 0.0, GradNorm: 236265515297800192.0\n",
            "x torch.Size([2, 410, 3])\n",
            "h[categorical] torch.Size([2, 410, 26])\n",
            "h[integer] torch.Size([2, 410, 1])\n",
            "Clipped gradient with value inf while allowed 292329.6\n",
            "Epoch: 0, iter: 18/34, Loss 1699334253390594048.00, NLL: 1699334253390594048.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 343, 3])\n",
            "h[categorical] torch.Size([2, 343, 26])\n",
            "h[integer] torch.Size([2, 343, 1])\n",
            "Clipped gradient with value inf while allowed 325598.7\n",
            "Epoch: 0, iter: 19/34, Loss 232697514166321152.00, NLL: 232697514166321152.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 169, 3])\n",
            "h[categorical] torch.Size([2, 169, 26])\n",
            "h[integer] torch.Size([2, 169, 1])\n",
            "Clipped gradient with value 7408414858674176.0 while allowed 361089.9\n",
            "Epoch: 0, iter: 20/34, Loss 639948554240.00, NLL: 639948554240.00, RegTerm: 0.0, GradNorm: 7408414858674176.0\n",
            "x torch.Size([2, 300, 3])\n",
            "h[categorical] torch.Size([2, 300, 26])\n",
            "h[integer] torch.Size([2, 300, 1])\n",
            "Clipped gradient with value 16827184336716431360.0 while allowed 398855.2\n",
            "Epoch: 0, iter: 21/34, Loss 4880297787129856.00, NLL: 4880297787129856.00, RegTerm: 0.0, GradNorm: 16827184336716431360.0\n",
            "x torch.Size([2, 306, 3])\n",
            "h[categorical] torch.Size([2, 306, 26])\n",
            "h[integer] torch.Size([2, 306, 1])\n",
            "Clipped gradient with value inf while allowed 438946.0\n",
            "Epoch: 0, iter: 22/34, Loss 56027101052010496.00, NLL: 56027101052010496.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 354, 3])\n",
            "h[categorical] torch.Size([2, 354, 26])\n",
            "h[integer] torch.Size([2, 354, 1])\n",
            "Clipped gradient with value inf while allowed 481412.5\n",
            "Epoch: 0, iter: 23/34, Loss 307088546756296704.00, NLL: 307088546756296704.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 364, 3])\n",
            "h[categorical] torch.Size([2, 364, 26])\n",
            "h[integer] torch.Size([2, 364, 1])\n",
            "Clipped gradient with value inf while allowed 526304.6\n",
            "Epoch: 0, iter: 24/34, Loss 12395493585846272.00, NLL: 12395493585846272.00, RegTerm: 0.0, GradNorm: inf\n",
            "x torch.Size([2, 325, 3])\n",
            "h[categorical] torch.Size([2, 325, 26])\n",
            "h[integer] torch.Size([2, 325, 1])\n",
            "Clipped gradient with value 38844624822861824.0 while allowed 573671.1\n",
            "Epoch: 0, iter: 25/34, Loss 36544232554496.00, NLL: 36544232554496.00, RegTerm: 0.0, GradNorm: 38844624822861824.0\n",
            "x torch.Size([2, 400, 3])\n",
            "h[categorical] torch.Size([2, 400, 26])\n",
            "h[integer] torch.Size([2, 400, 1])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[0;32m----> 4\u001b[0m     nll_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_ema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnodes_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mgradnorm_queue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradnorm_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprop_dist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     train_loss[epoch] \u001b[38;5;241m=\u001b[39m nll_train\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mtest_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/train_test.py:62\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(args, loader, epoch, model, model_dp, model_ema, ema, device, dtype, property_norms, optim, nodes_dist, gradnorm_queue, dataset_info, prop_dist)\u001b[0m\n\u001b[1;32m     59\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# transform batch through flow\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m nll, reg_term, mean_abs_z \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss_and_nll\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_dist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# standard nll from forward KL\u001b[39;00m\n\u001b[1;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m nll \u001b[38;5;241m+\u001b[39m args\u001b[38;5;241m.\u001b[39mode_regularization \u001b[38;5;241m*\u001b[39m reg_term\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/losses.py:23\u001b[0m, in \u001b[0;36mcompute_loss_and_nll\u001b[0;34m(args, generative_model, nodes_dist, x, h, node_mask, edge_mask, context)\u001b[0m\n\u001b[1;32m     19\u001b[0m assert_correctly_masked(x, node_mask)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Here x is a position tensor, and h is a dictionary with keys\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 'categorical' and 'integer'.\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m nll \u001b[38;5;241m=\u001b[39m \u001b[43mgenerative_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m N \u001b[38;5;241m=\u001b[39m node_mask\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     27\u001b[0m log_pN \u001b[38;5;241m=\u001b[39m nodes_dist\u001b[38;5;241m.\u001b[39mlog_prob(N)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/equivariant_diffusion/en_diffusion.py:710\u001b[0m, in \u001b[0;36mEnVariationalDiffusion.forward\u001b[0;34m(self, x, h, node_mask, edge_mask, context)\u001b[0m\n\u001b[1;32m    706\u001b[0m     delta_log_px \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(delta_log_px)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# Only 1 forward pass when t0_always is False.\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     loss, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0_always\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# Less variance in the estimator, costs two forward passes.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     loss, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, h, node_mask, edge_mask, context, t0_always\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/equivariant_diffusion/en_diffusion.py:618\u001b[0m, in \u001b[0;36mEnVariationalDiffusion.compute_loss\u001b[0;34m(self, x, h, node_mask, edge_mask, context, t0_always)\u001b[0m\n\u001b[1;32m    615\u001b[0m diffusion_utils\u001b[38;5;241m.\u001b[39massert_mean_zero_with_mask(z_t[:, :, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dims], node_mask)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Neural net prediction.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# Compute the error.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_error(net_out, gamma_t, eps)\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/equivariant_diffusion/en_diffusion.py:315\u001b[0m, in \u001b[0;36mEnVariationalDiffusion.phi\u001b[0;34m(self, x, t, node_mask, edge_mask, context)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphi\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, node_mask, edge_mask, context):\n\u001b[0;32m--> 315\u001b[0m     net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net_out\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/egnn/models.py:79\u001b[0m, in \u001b[0;36mEGNN_dynamics_QM9._forward\u001b[0;34m(self, t, xh, node_mask, edge_mask, context)\u001b[0m\n\u001b[1;32m     76\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h, context], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124megnn_dynamics\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 79\u001b[0m     h_final, x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43megnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     vel \u001b[38;5;241m=\u001b[39m (x_final \u001b[38;5;241m-\u001b[39m x) \u001b[38;5;241m*\u001b[39m node_mask  \u001b[38;5;66;03m# This masking operation is redundant but just in case\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgnn_dynamics\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/egnn/egnn_new.py:191\u001b[0m, in \u001b[0;36mEGNN.forward\u001b[0;34m(self, h, x, edge_index, node_mask, edge_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(h)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m--> 191\u001b[0m     h, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43me_block_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Important, the bias of the last linear might be non-zero\u001b[39;00m\n\u001b[1;32m    194\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_out(h)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/egnn/egnn_new.py:141\u001b[0m, in \u001b[0;36mEquivariantBlock.forward\u001b[0;34m(self, h, x, edge_index, node_mask, edge_mask, edge_attr)\u001b[0m\n\u001b[1;32m    139\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([distances, edge_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m--> 141\u001b[0m     h, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgcl_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcl_equiv\u001b[39m\u001b[38;5;124m\"\u001b[39m](h, x, edge_index, coord_diff, edge_attr, node_mask, edge_mask)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Important, the bias of the last linear might be non-zero\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/egnn/egnn_new.py:61\u001b[0m, in \u001b[0;36mGCL.forward\u001b[0;34m(self, h, edge_index, edge_attr, node_attr, node_mask, edge_mask)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, h, edge_index, edge_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, node_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, node_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, edge_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[0;32m---> 61\u001b[0m     edge_feat, mij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     h, agg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_model(h, edge_index, edge_feat, node_attr)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/Documents/NUS Computing/02 CS5284 - Graph Machine Learning/Project/protein-coordinates/notebooks/../src/models/egnn/egnn_new.py:38\u001b[0m, in \u001b[0;36mGCL.edge_model\u001b[0;34m(self, source, target, edge_attr, edge_mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m mij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mlp(out)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention:\n\u001b[0;32m---> 38\u001b[0m     att_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmij\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     out \u001b[38;5;241m=\u001b[39m mij \u001b[38;5;241m*\u001b[39m att_val\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/gvp/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_loss = {}\n",
        "test_loss = {}\n",
        "for epoch in range(args.n_epochs):\n",
        "    nll_train = train_epoch(args=args, loader=train_dataloader, epoch=epoch, model=model, model_dp=model,\n",
        "                    model_ema=model, ema=None, device=device, dtype=torch.float32, property_norms=None,\n",
        "                    nodes_dist=nodes_dist, dataset_info=dataset_info,\n",
        "                    gradnorm_queue=gradnorm_queue, optim=optim, prop_dist=prop_dist)\n",
        "    train_loss[epoch] = nll_train\n",
        "    if epoch % args.test_epochs == 0:\n",
        "        nll_test = test(args=args, loader=test_dataloader, epoch=epoch, eval_model=model,\n",
        "                        partition='Test', device=device, dtype=torch.float32,\n",
        "                        nodes_dist=nodes_dist, property_norms=None)\n",
        "        test_loss[epoch] = nll_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry6pDAnKZYJl"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RVVuE8-ADxHH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
